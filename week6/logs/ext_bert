[2021-06-05 22:02:20,639 INFO] Device ID 0
[2021-06-05 22:02:20,856 INFO] Device cuda
[2021-06-05 22:02:54,408 INFO] Device ID 0
[2021-06-05 22:02:54,796 INFO] Device cuda
[2021-06-05 22:04:07,183 INFO] Device ID 0
[2021-06-05 22:04:07,183 INFO] Device cuda
[2021-06-05 22:06:18,135 INFO] Device ID 0
[2021-06-05 22:06:18,136 INFO] Device cuda
[2021-06-05 22:12:05,698 INFO] ExtSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=1)
        (position_embeddings): Embedding(800, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (ext_layer): ExtTransformerEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2021-06-05 22:12:11,445 INFO] * number of parameters: 113519105
[2021-06-05 22:12:23,648 INFO] Start training...
[2021-06-05 22:13:41,879 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-05 22:25:31,764 INFO] Device ID 0
[2021-06-05 22:25:31,764 INFO] Device cuda
[2021-06-05 22:25:35,422 INFO] ExtSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=1)
        (position_embeddings): Embedding(800, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (ext_layer): ExtTransformerEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2021-06-05 22:25:35,443 INFO] * number of parameters: 113519105
[2021-06-05 22:25:35,444 INFO] Start training...
[2021-06-05 22:25:43,013 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-05 22:31:24,347 INFO] Device ID 0
[2021-06-05 22:31:24,347 INFO] Device cuda
[2021-06-05 22:31:28,391 INFO] ExtSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=1)
        (position_embeddings): Embedding(800, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (ext_layer): ExtTransformerEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2021-06-05 22:31:28,411 INFO] * number of parameters: 113519105
[2021-06-05 22:31:28,412 INFO] Start training...
[2021-06-05 22:31:47,200 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-05 22:52:38,685 INFO] Device ID 0
[2021-06-05 22:52:38,685 INFO] Device cuda
[2021-06-05 22:52:43,692 INFO] ExtSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=1)
        (position_embeddings): Embedding(800, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (ext_layer): ExtTransformerEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2021-06-05 22:52:43,716 INFO] * number of parameters: 113519105
[2021-06-05 22:52:43,717 INFO] Start training...
[2021-06-05 22:52:48,355 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-05 23:02:41,124 INFO] Device ID 0
[2021-06-05 23:02:41,125 INFO] Device cuda
[2021-06-05 23:02:44,881 INFO] ExtSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=1)
        (position_embeddings): Embedding(800, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (ext_layer): ExtTransformerEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2021-06-05 23:02:44,899 INFO] * number of parameters: 113519105
[2021-06-05 23:02:44,900 INFO] Start training...
[2021-06-05 23:02:48,426 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-05 23:05:44,623 INFO] Device ID 0
[2021-06-05 23:05:44,623 INFO] Device cuda
[2021-06-05 23:05:48,486 INFO] ExtSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=1)
        (position_embeddings): Embedding(800, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (ext_layer): ExtTransformerEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2021-06-05 23:05:48,508 INFO] * number of parameters: 113519105
[2021-06-05 23:05:48,508 INFO] Start training...
[2021-06-05 23:05:58,483 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-05 23:08:54,324 INFO] Device ID 0
[2021-06-05 23:08:54,324 INFO] Device cuda
[2021-06-05 23:08:58,755 INFO] ExtSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=1)
        (position_embeddings): Embedding(800, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (ext_layer): ExtTransformerEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2021-06-05 23:08:58,778 INFO] * number of parameters: 113519105
[2021-06-05 23:08:58,778 INFO] Start training...
[2021-06-05 23:09:19,239 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-05 23:45:28,002 INFO] Device ID 0
[2021-06-05 23:45:28,002 INFO] Device cuda
[2021-06-05 23:45:32,633 INFO] ExtSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=1)
        (position_embeddings): Embedding(800, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (ext_layer): ExtTransformerEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2021-06-05 23:45:32,652 INFO] * number of parameters: 113519105
[2021-06-05 23:45:32,653 INFO] Start training...
[2021-06-05 23:45:40,865 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-05 23:53:39,497 INFO] Device ID 0
[2021-06-05 23:53:39,497 INFO] Device cuda
[2021-06-05 23:53:43,163 INFO] ExtSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=1)
        (position_embeddings): Embedding(800, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (ext_layer): ExtTransformerEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2021-06-05 23:53:43,187 INFO] * number of parameters: 113519105
[2021-06-05 23:53:43,188 INFO] Start training...
[2021-06-05 23:53:46,987 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-05 23:56:22,276 INFO] Device ID 0
[2021-06-05 23:56:22,276 INFO] Device cuda
[2021-06-05 23:56:25,927 INFO] ExtSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=1)
        (position_embeddings): Embedding(800, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (ext_layer): ExtTransformerEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2021-06-05 23:56:25,946 INFO] * number of parameters: 113519105
[2021-06-05 23:56:25,947 INFO] Start training...
[2021-06-05 23:56:30,424 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-06 00:01:45,706 INFO] Device ID 0
[2021-06-06 00:01:45,706 INFO] Device cuda
[2021-06-06 00:01:48,827 INFO] ExtSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=1)
        (position_embeddings): Embedding(800, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (ext_layer): ExtTransformerEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2021-06-06 00:01:48,835 INFO] * number of parameters: 113519105
[2021-06-06 00:01:48,835 INFO] Start training...
[2021-06-06 00:01:50,421 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-06 00:03:21,775 INFO] Device ID 0
[2021-06-06 00:03:21,775 INFO] Device cuda
[2021-06-06 00:03:24,908 INFO] ExtSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(21128, 768, padding_idx=1)
        (position_embeddings): Embedding(800, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (ext_layer): ExtTransformerEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (dropout): Dropout(p=0.1, inplace=False)
    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2021-06-06 00:03:24,916 INFO] * number of parameters: 113519105
[2021-06-06 00:03:24,916 INFO] Start training...
[2021-06-06 00:03:26,515 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-06 00:03:44,778 INFO] Step 50/50000; xent: 3.76; lr: 0.0000001;  33 docs/s;     18 sec
[2021-06-06 00:04:02,873 INFO] Step 100/50000; xent: 3.58; lr: 0.0000003;  36 docs/s;     36 sec
[2021-06-06 00:04:20,855 INFO] Step 150/50000; xent: 3.35; lr: 0.0000004;  37 docs/s;     54 sec
[2021-06-06 00:04:38,532 INFO] Step 200/50000; xent: 3.45; lr: 0.0000006;  32 docs/s;     72 sec
[2021-06-06 00:04:56,227 INFO] Step 250/50000; xent: 3.31; lr: 0.0000008;  34 docs/s;     90 sec
[2021-06-06 00:05:14,362 INFO] Step 300/50000; xent: 3.22; lr: 0.0000009;  37 docs/s;    108 sec
[2021-06-06 00:05:32,453 INFO] Step 350/50000; xent: 3.34; lr: 0.0000011;  33 docs/s;    126 sec
[2021-06-06 00:05:50,839 INFO] Step 400/50000; xent: 3.15; lr: 0.0000012;  37 docs/s;    144 sec
[2021-06-06 00:06:08,866 INFO] Step 450/50000; xent: 3.07; lr: 0.0000013;  36 docs/s;    162 sec
[2021-06-06 00:06:27,414 INFO] Step 500/50000; xent: 3.10; lr: 0.0000015;  36 docs/s;    181 sec
[2021-06-06 00:06:45,600 INFO] Step 550/50000; xent: 3.05; lr: 0.0000016;  36 docs/s;    199 sec
[2021-06-06 00:07:03,588 INFO] Step 600/50000; xent: 3.23; lr: 0.0000018;  31 docs/s;    217 sec
[2021-06-06 00:07:21,620 INFO] Step 650/50000; xent: 3.07; lr: 0.0000019;  34 docs/s;    235 sec
[2021-06-06 00:07:39,949 INFO] Step 700/50000; xent: 2.94; lr: 0.0000021;  35 docs/s;    253 sec
[2021-06-06 00:07:58,397 INFO] Step 750/50000; xent: 3.18; lr: 0.0000023;  31 docs/s;    272 sec
[2021-06-06 00:08:16,731 INFO] Step 800/50000; xent: 2.80; lr: 0.0000024;  40 docs/s;    290 sec
[2021-06-06 00:08:35,241 INFO] Step 850/50000; xent: 3.03; lr: 0.0000025;  31 docs/s;    309 sec
[2021-06-06 00:08:53,195 INFO] Step 900/50000; xent: 2.95; lr: 0.0000027;  35 docs/s;    327 sec
[2021-06-06 00:09:10,973 INFO] Step 950/50000; xent: 3.08; lr: 0.0000029;  33 docs/s;    344 sec
[2021-06-06 00:09:29,407 INFO] Step 1000/50000; xent: 2.85; lr: 0.0000030;  35 docs/s;    363 sec
[2021-06-06 00:09:47,764 INFO] Step 1050/50000; xent: 3.07; lr: 0.0000031;  33 docs/s;    381 sec
[2021-06-06 00:10:06,220 INFO] Step 1100/50000; xent: 2.94; lr: 0.0000033;  36 docs/s;    400 sec
[2021-06-06 00:10:24,558 INFO] Step 1150/50000; xent: 3.15; lr: 0.0000035;  33 docs/s;    418 sec
[2021-06-06 00:10:42,709 INFO] Step 1200/50000; xent: 2.86; lr: 0.0000036;  33 docs/s;    436 sec
[2021-06-06 00:11:01,146 INFO] Step 1250/50000; xent: 2.88; lr: 0.0000038;  36 docs/s;    455 sec
[2021-06-06 00:11:19,072 INFO] Step 1300/50000; xent: 2.85; lr: 0.0000039;  35 docs/s;    473 sec
[2021-06-06 00:11:37,237 INFO] Step 1350/50000; xent: 2.88; lr: 0.0000040;  37 docs/s;    491 sec
[2021-06-06 00:11:55,684 INFO] Step 1400/50000; xent: 3.08; lr: 0.0000042;  32 docs/s;    509 sec
[2021-06-06 00:12:13,786 INFO] Step 1450/50000; xent: 3.26; lr: 0.0000043;  30 docs/s;    527 sec
[2021-06-06 00:12:31,947 INFO] Step 1500/50000; xent: 2.89; lr: 0.0000045;  37 docs/s;    545 sec
[2021-06-06 00:12:50,251 INFO] Step 1550/50000; xent: 2.93; lr: 0.0000046;  34 docs/s;    564 sec
[2021-06-06 00:13:08,352 INFO] Step 1600/50000; xent: 3.09; lr: 0.0000048;  31 docs/s;    582 sec
[2021-06-06 00:13:26,461 INFO] Step 1650/50000; xent: 3.15; lr: 0.0000050;  32 docs/s;    600 sec
[2021-06-06 00:13:44,926 INFO] Step 1700/50000; xent: 2.78; lr: 0.0000051;  39 docs/s;    618 sec
[2021-06-06 00:14:03,177 INFO] Step 1750/50000; xent: 2.94; lr: 0.0000052;  33 docs/s;    637 sec
[2021-06-06 00:14:21,503 INFO] Step 1800/50000; xent: 3.08; lr: 0.0000054;  33 docs/s;    655 sec
[2021-06-06 00:14:39,811 INFO] Step 1850/50000; xent: 2.93; lr: 0.0000055;  36 docs/s;    673 sec
[2021-06-06 00:14:57,889 INFO] Step 1900/50000; xent: 2.92; lr: 0.0000057;  34 docs/s;    691 sec
[2021-06-06 00:15:16,321 INFO] Step 1950/50000; xent: 3.20; lr: 0.0000058;  29 docs/s;    710 sec
[2021-06-06 00:15:34,564 INFO] Step 2000/50000; xent: 3.09; lr: 0.0000060;  33 docs/s;    728 sec
[2021-06-06 00:15:52,856 INFO] Step 2050/50000; xent: 2.84; lr: 0.0000061;  34 docs/s;    746 sec
[2021-06-06 00:16:11,282 INFO] Step 2100/50000; xent: 2.85; lr: 0.0000063;  35 docs/s;    765 sec
[2021-06-06 00:16:29,179 INFO] Step 2150/50000; xent: 3.06; lr: 0.0000065;  35 docs/s;    783 sec
[2021-06-06 00:16:47,619 INFO] Step 2200/50000; xent: 2.82; lr: 0.0000066;  37 docs/s;    801 sec
[2021-06-06 00:17:05,695 INFO] Step 2250/50000; xent: 3.00; lr: 0.0000067;  33 docs/s;    819 sec
[2021-06-06 00:17:23,937 INFO] Step 2300/50000; xent: 2.84; lr: 0.0000069;  35 docs/s;    837 sec
[2021-06-06 00:17:42,310 INFO] Step 2350/50000; xent: 2.83; lr: 0.0000071;  35 docs/s;    856 sec
[2021-06-06 00:18:00,785 INFO] Step 2400/50000; xent: 2.93; lr: 0.0000072;  35 docs/s;    874 sec
[2021-06-06 00:18:19,332 INFO] Step 2450/50000; xent: 2.84; lr: 0.0000073;  34 docs/s;    893 sec
[2021-06-06 00:18:37,749 INFO] Step 2500/50000; xent: 3.01; lr: 0.0000075;  32 docs/s;    911 sec
[2021-06-06 00:18:52,119 INFO] Loading train dataset from ../bert_data/train.2.bert.pt, number of examples: 15944
[2021-06-06 00:18:58,006 INFO] Step 2550/50000; xent: 2.76; lr: 0.0000076;  30 docs/s;    931 sec
[2021-06-06 00:19:16,244 INFO] Step 2600/50000; xent: 3.03; lr: 0.0000078;  34 docs/s;    950 sec
[2021-06-06 00:19:34,739 INFO] Step 2650/50000; xent: 2.78; lr: 0.0000080;  36 docs/s;    968 sec
[2021-06-06 00:19:52,999 INFO] Step 2700/50000; xent: 2.88; lr: 0.0000081;  36 docs/s;    986 sec
[2021-06-06 00:20:11,377 INFO] Step 2750/50000; xent: 2.90; lr: 0.0000082;  32 docs/s;   1005 sec
[2021-06-06 00:20:29,919 INFO] Step 2800/50000; xent: 2.73; lr: 0.0000084;  38 docs/s;   1023 sec
[2021-06-06 00:20:48,582 INFO] Step 2850/50000; xent: 2.76; lr: 0.0000085;  35 docs/s;   1042 sec
[2021-06-06 00:21:07,031 INFO] Step 2900/50000; xent: 2.82; lr: 0.0000087;  34 docs/s;   1061 sec
[2021-06-06 00:21:25,489 INFO] Step 2950/50000; xent: 2.97; lr: 0.0000088;  35 docs/s;   1079 sec
[2021-06-06 00:21:43,829 INFO] Step 3000/50000; xent: 2.78; lr: 0.0000090;  36 docs/s;   1097 sec
[2021-06-06 00:22:01,930 INFO] Step 3050/50000; xent: 2.85; lr: 0.0000091;  35 docs/s;   1115 sec
[2021-06-06 00:22:20,335 INFO] Step 3100/50000; xent: 3.09; lr: 0.0000093;  32 docs/s;   1134 sec
[2021-06-06 00:22:38,642 INFO] Step 3150/50000; xent: 2.46; lr: 0.0000095;  41 docs/s;   1152 sec
[2021-06-06 00:22:56,895 INFO] Step 3200/50000; xent: 3.01; lr: 0.0000096;  31 docs/s;   1170 sec
[2021-06-06 00:23:15,250 INFO] Step 3250/50000; xent: 2.81; lr: 0.0000097;  37 docs/s;   1189 sec
[2021-06-06 00:23:33,648 INFO] Step 3300/50000; xent: 2.68; lr: 0.0000099;  33 docs/s;   1207 sec
[2021-06-06 00:23:52,158 INFO] Step 3350/50000; xent: 2.76; lr: 0.0000100;  36 docs/s;   1226 sec
[2021-06-06 00:24:10,642 INFO] Step 3400/50000; xent: 2.94; lr: 0.0000102;  31 docs/s;   1244 sec
[2021-06-06 00:24:28,765 INFO] Step 3450/50000; xent: 2.88; lr: 0.0000104;  35 docs/s;   1262 sec
[2021-06-06 00:24:47,208 INFO] Step 3500/50000; xent: 2.64; lr: 0.0000105;  39 docs/s;   1281 sec
[2021-06-06 00:25:05,168 INFO] Step 3550/50000; xent: 2.90; lr: 0.0000106;  33 docs/s;   1299 sec
[2021-06-06 00:25:23,613 INFO] Step 3600/50000; xent: 3.27; lr: 0.0000108;  30 docs/s;   1317 sec
[2021-06-06 00:25:41,989 INFO] Step 3650/50000; xent: 2.86; lr: 0.0000110;  34 docs/s;   1335 sec
[2021-06-06 00:26:00,252 INFO] Step 3700/50000; xent: 2.71; lr: 0.0000111;  39 docs/s;   1354 sec
[2021-06-06 00:26:18,320 INFO] Step 3750/50000; xent: 2.93; lr: 0.0000112;  32 docs/s;   1372 sec
[2021-06-06 00:26:36,921 INFO] Step 3800/50000; xent: 2.72; lr: 0.0000114;  38 docs/s;   1390 sec
[2021-06-06 00:26:55,310 INFO] Step 3850/50000; xent: 2.74; lr: 0.0000115;  38 docs/s;   1409 sec
[2021-06-06 00:27:13,310 INFO] Step 3900/50000; xent: 2.70; lr: 0.0000117;  34 docs/s;   1427 sec
[2021-06-06 00:27:31,511 INFO] Step 3950/50000; xent: 2.83; lr: 0.0000118;  36 docs/s;   1445 sec
[2021-06-06 00:27:49,842 INFO] Step 4000/50000; xent: 2.91; lr: 0.0000120;  33 docs/s;   1463 sec
[2021-06-06 00:28:08,128 INFO] Step 4050/50000; xent: 2.82; lr: 0.0000121;  36 docs/s;   1482 sec
[2021-06-06 00:28:26,504 INFO] Step 4100/50000; xent: 3.01; lr: 0.0000123;  34 docs/s;   1500 sec
[2021-06-06 00:28:44,881 INFO] Step 4150/50000; xent: 2.74; lr: 0.0000125;  38 docs/s;   1518 sec
[2021-06-06 00:29:03,573 INFO] Step 4200/50000; xent: 2.80; lr: 0.0000126;  33 docs/s;   1537 sec
[2021-06-06 00:29:22,021 INFO] Step 4250/50000; xent: 2.72; lr: 0.0000127;  37 docs/s;   1556 sec
[2021-06-06 00:29:40,116 INFO] Step 4300/50000; xent: 2.64; lr: 0.0000129;  37 docs/s;   1574 sec
[2021-06-06 00:29:58,158 INFO] Step 4350/50000; xent: 2.89; lr: 0.0000130;  34 docs/s;   1592 sec
[2021-06-06 00:30:16,614 INFO] Step 4400/50000; xent: 2.81; lr: 0.0000132;  37 docs/s;   1610 sec
[2021-06-06 00:30:34,895 INFO] Step 4450/50000; xent: 2.97; lr: 0.0000134;  34 docs/s;   1628 sec
[2021-06-06 00:30:53,094 INFO] Step 4500/50000; xent: 2.81; lr: 0.0000135;  36 docs/s;   1647 sec
[2021-06-06 00:31:11,513 INFO] Step 4550/50000; xent: 2.76; lr: 0.0000137;  38 docs/s;   1665 sec
[2021-06-06 00:31:29,799 INFO] Step 4600/50000; xent: 2.67; lr: 0.0000138;  39 docs/s;   1683 sec
[2021-06-06 00:31:47,986 INFO] Step 4650/50000; xent: 2.62; lr: 0.0000139;  36 docs/s;   1701 sec
[2021-06-06 00:32:06,392 INFO] Step 4700/50000; xent: 2.77; lr: 0.0000141;  36 docs/s;   1720 sec
[2021-06-06 00:32:24,820 INFO] Step 4750/50000; xent: 2.91; lr: 0.0000143;  34 docs/s;   1738 sec
[2021-06-06 00:32:43,081 INFO] Step 4800/50000; xent: 2.71; lr: 0.0000144;  36 docs/s;   1757 sec
[2021-06-06 00:33:01,673 INFO] Step 4850/50000; xent: 2.75; lr: 0.0000146;  36 docs/s;   1775 sec
[2021-06-06 00:33:20,082 INFO] Step 4900/50000; xent: 2.69; lr: 0.0000147;  35 docs/s;   1794 sec
[2021-06-06 00:33:38,718 INFO] Step 4950/50000; xent: 2.80; lr: 0.0000148;  36 docs/s;   1812 sec
[2021-06-06 00:33:56,596 INFO] Loading train dataset from ../bert_data/train.1.bert.pt, number of examples: 15951
[2021-06-06 00:33:58,682 INFO] Step 5000/50000; xent: 2.85; lr: 0.0000150;  29 docs/s;   1832 sec
[2021-06-06 00:33:58,684 INFO] Saving checkpoint ../models/bert_ext\model_step_5000.pt
[2021-06-06 00:34:22,999 INFO] Step 5050/50000; xent: 2.80; lr: 0.0000151;  29 docs/s;   1856 sec
[2021-06-06 00:34:40,933 INFO] Step 5100/50000; xent: 2.74; lr: 0.0000153;  36 docs/s;   1874 sec
[2021-06-06 00:34:58,773 INFO] Step 5150/50000; xent: 2.66; lr: 0.0000154;  35 docs/s;   1892 sec
[2021-06-06 00:35:17,072 INFO] Step 5200/50000; xent: 2.91; lr: 0.0000156;  33 docs/s;   1911 sec
[2021-06-06 00:35:35,397 INFO] Step 5250/50000; xent: 2.61; lr: 0.0000157;  40 docs/s;   1929 sec
[2021-06-06 00:35:53,827 INFO] Step 5300/50000; xent: 3.02; lr: 0.0000159;  31 docs/s;   1947 sec
[2021-06-06 00:36:12,090 INFO] Step 5350/50000; xent: 2.68; lr: 0.0000161;  36 docs/s;   1966 sec
[2021-06-06 00:36:29,821 INFO] Step 5400/50000; xent: 2.79; lr: 0.0000162;  36 docs/s;   1983 sec
[2021-06-06 00:36:48,978 INFO] Step 5450/50000; xent: 2.88; lr: 0.0000164;  32 docs/s;   2002 sec
[2021-06-06 00:37:07,873 INFO] Step 5500/50000; xent: 2.87; lr: 0.0000165;  30 docs/s;   2021 sec
[2021-06-06 00:37:26,236 INFO] Step 5550/50000; xent: 2.61; lr: 0.0000166;  38 docs/s;   2040 sec
[2021-06-06 00:37:44,752 INFO] Step 5600/50000; xent: 2.73; lr: 0.0000168;  35 docs/s;   2058 sec
[2021-06-06 00:38:02,991 INFO] Step 5650/50000; xent: 2.60; lr: 0.0000169;  35 docs/s;   2076 sec
[2021-06-06 00:38:21,291 INFO] Step 5700/50000; xent: 2.79; lr: 0.0000171;  34 docs/s;   2095 sec
[2021-06-06 00:38:39,769 INFO] Step 5750/50000; xent: 2.68; lr: 0.0000172;  36 docs/s;   2113 sec
[2021-06-06 00:38:58,185 INFO] Step 5800/50000; xent: 2.70; lr: 0.0000174;  36 docs/s;   2132 sec
[2021-06-06 00:39:16,394 INFO] Step 5850/50000; xent: 2.83; lr: 0.0000175;  32 docs/s;   2150 sec
[2021-06-06 00:39:34,688 INFO] Step 5900/50000; xent: 2.81; lr: 0.0000177;  33 docs/s;   2168 sec
[2021-06-06 00:39:52,986 INFO] Step 5950/50000; xent: 2.82; lr: 0.0000179;  33 docs/s;   2186 sec
[2021-06-06 00:40:11,110 INFO] Step 6000/50000; xent: 2.83; lr: 0.0000180;  33 docs/s;   2205 sec
[2021-06-06 00:40:29,340 INFO] Step 6050/50000; xent: 2.73; lr: 0.0000182;  35 docs/s;   2223 sec
[2021-06-06 00:40:47,985 INFO] Step 6100/50000; xent: 2.64; lr: 0.0000183;  37 docs/s;   2241 sec
[2021-06-06 00:41:06,260 INFO] Step 6150/50000; xent: 2.91; lr: 0.0000185;  33 docs/s;   2260 sec
[2021-06-06 00:41:25,073 INFO] Step 6200/50000; xent: 2.59; lr: 0.0000186;  35 docs/s;   2279 sec
[2021-06-06 00:41:43,730 INFO] Step 6250/50000; xent: 2.78; lr: 0.0000187;  32 docs/s;   2297 sec
[2021-06-06 00:42:02,382 INFO] Step 6300/50000; xent: 2.78; lr: 0.0000189;  32 docs/s;   2316 sec
[2021-06-06 00:42:20,412 INFO] Step 6350/50000; xent: 2.91; lr: 0.0000190;  34 docs/s;   2334 sec
[2021-06-06 00:42:38,714 INFO] Step 6400/50000; xent: 2.75; lr: 0.0000192;  36 docs/s;   2352 sec
[2021-06-06 00:42:57,471 INFO] Step 6450/50000; xent: 2.78; lr: 0.0000193;  30 docs/s;   2371 sec
[2021-06-06 00:43:15,728 INFO] Step 6500/50000; xent: 2.87; lr: 0.0000195;  31 docs/s;   2389 sec
[2021-06-06 00:43:34,140 INFO] Step 6550/50000; xent: 2.62; lr: 0.0000196;  36 docs/s;   2408 sec
[2021-06-06 00:43:52,583 INFO] Step 6600/50000; xent: 2.73; lr: 0.0000198;  36 docs/s;   2426 sec
[2021-06-06 00:44:10,874 INFO] Step 6650/50000; xent: 2.71; lr: 0.0000200;  39 docs/s;   2444 sec
[2021-06-06 00:44:29,164 INFO] Step 6700/50000; xent: 2.68; lr: 0.0000201;  39 docs/s;   2463 sec
[2021-06-06 00:44:47,547 INFO] Step 6750/50000; xent: 2.75; lr: 0.0000203;  34 docs/s;   2481 sec
[2021-06-06 00:45:05,682 INFO] Step 6800/50000; xent: 2.75; lr: 0.0000204;  34 docs/s;   2499 sec
[2021-06-06 00:45:24,323 INFO] Step 6850/50000; xent: 2.68; lr: 0.0000205;  35 docs/s;   2518 sec
[2021-06-06 00:45:43,091 INFO] Step 6900/50000; xent: 2.98; lr: 0.0000207;  32 docs/s;   2537 sec
[2021-06-06 00:46:01,897 INFO] Step 6950/50000; xent: 2.87; lr: 0.0000208;  33 docs/s;   2555 sec
[2021-06-06 00:46:20,301 INFO] Step 7000/50000; xent: 2.79; lr: 0.0000210;  34 docs/s;   2574 sec
[2021-06-06 00:46:38,690 INFO] Step 7050/50000; xent: 2.68; lr: 0.0000211;  35 docs/s;   2592 sec
[2021-06-06 00:46:57,198 INFO] Step 7100/50000; xent: 2.85; lr: 0.0000213;  33 docs/s;   2611 sec
[2021-06-06 00:47:15,367 INFO] Step 7150/50000; xent: 2.84; lr: 0.0000214;  33 docs/s;   2629 sec
[2021-06-06 00:47:33,865 INFO] Step 7200/50000; xent: 2.75; lr: 0.0000216;  32 docs/s;   2647 sec
[2021-06-06 00:47:52,163 INFO] Step 7250/50000; xent: 2.55; lr: 0.0000218;  38 docs/s;   2666 sec
[2021-06-06 00:48:10,562 INFO] Step 7300/50000; xent: 2.65; lr: 0.0000219;  37 docs/s;   2684 sec
[2021-06-06 00:48:28,636 INFO] Step 7350/50000; xent: 2.66; lr: 0.0000221;  36 docs/s;   2702 sec
[2021-06-06 00:48:47,160 INFO] Step 7400/50000; xent: 2.67; lr: 0.0000222;  37 docs/s;   2721 sec
[2021-06-06 00:49:05,444 INFO] Step 7450/50000; xent: 3.11; lr: 0.0000224;  31 docs/s;   2739 sec
[2021-06-06 00:49:23,467 INFO] Step 7500/50000; xent: 2.58; lr: 0.0000225;  37 docs/s;   2757 sec
[2021-06-06 00:49:28,948 INFO] Loading train dataset from ../bert_data/train.4.bert.pt, number of examples: 15873
[2021-06-06 00:49:43,984 INFO] Step 7550/50000; xent: 2.73; lr: 0.0000226;  33 docs/s;   2777 sec
[2021-06-06 00:50:02,317 INFO] Step 7600/50000; xent: 3.10; lr: 0.0000228;  30 docs/s;   2796 sec
[2021-06-06 00:50:20,841 INFO] Step 7650/50000; xent: 2.87; lr: 0.0000229;  32 docs/s;   2814 sec
[2021-06-06 00:50:39,503 INFO] Step 7700/50000; xent: 2.53; lr: 0.0000231;  37 docs/s;   2833 sec
[2021-06-06 00:50:58,029 INFO] Step 7750/50000; xent: 3.05; lr: 0.0000232;  30 docs/s;   2852 sec
[2021-06-06 00:51:16,351 INFO] Step 7800/50000; xent: 2.60; lr: 0.0000234;  38 docs/s;   2870 sec
[2021-06-06 00:51:34,651 INFO] Step 7850/50000; xent: 2.88; lr: 0.0000235;  32 docs/s;   2888 sec
[2021-06-06 00:51:52,912 INFO] Step 7900/50000; xent: 2.66; lr: 0.0000237;  35 docs/s;   2906 sec
[2021-06-06 00:52:11,206 INFO] Step 7950/50000; xent: 2.87; lr: 0.0000239;  29 docs/s;   2925 sec
[2021-06-06 00:52:29,827 INFO] Step 8000/50000; xent: 2.68; lr: 0.0000240;  36 docs/s;   2943 sec
[2021-06-06 00:52:48,428 INFO] Step 8050/50000; xent: 2.63; lr: 0.0000242;  37 docs/s;   2962 sec
[2021-06-06 00:53:06,811 INFO] Step 8100/50000; xent: 2.91; lr: 0.0000243;  33 docs/s;   2980 sec
[2021-06-06 00:53:25,520 INFO] Step 8150/50000; xent: 2.53; lr: 0.0000244;  37 docs/s;   2999 sec
[2021-06-06 00:53:43,570 INFO] Step 8200/50000; xent: 2.75; lr: 0.0000246;  33 docs/s;   3017 sec
[2021-06-06 00:54:02,198 INFO] Step 8250/50000; xent: 2.88; lr: 0.0000248;  33 docs/s;   3036 sec
[2021-06-06 00:54:20,444 INFO] Step 8300/50000; xent: 2.78; lr: 0.0000249;  35 docs/s;   3054 sec
[2021-06-06 00:54:38,897 INFO] Step 8350/50000; xent: 2.71; lr: 0.0000250;  34 docs/s;   3072 sec
[2021-06-06 00:54:57,724 INFO] Step 8400/50000; xent: 2.64; lr: 0.0000252;  36 docs/s;   3091 sec
[2021-06-06 00:55:15,902 INFO] Step 8450/50000; xent: 2.68; lr: 0.0000253;  36 docs/s;   3109 sec
[2021-06-06 00:55:34,272 INFO] Step 8500/50000; xent: 2.61; lr: 0.0000255;  36 docs/s;   3128 sec
[2021-06-06 00:55:52,747 INFO] Step 8550/50000; xent: 2.62; lr: 0.0000257;  34 docs/s;   3146 sec
[2021-06-06 00:56:10,830 INFO] Step 8600/50000; xent: 2.94; lr: 0.0000258;  33 docs/s;   3164 sec
[2021-06-06 00:56:28,896 INFO] Step 8650/50000; xent: 2.61; lr: 0.0000260;  37 docs/s;   3182 sec
[2021-06-06 00:56:47,196 INFO] Step 8700/50000; xent: 2.71; lr: 0.0000261;  37 docs/s;   3201 sec
[2021-06-06 00:57:05,495 INFO] Step 8750/50000; xent: 2.66; lr: 0.0000262;  34 docs/s;   3219 sec
[2021-06-06 00:57:23,759 INFO] Step 8800/50000; xent: 2.88; lr: 0.0000264;  32 docs/s;   3237 sec
[2021-06-06 00:57:42,165 INFO] Step 8850/50000; xent: 2.58; lr: 0.0000266;  36 docs/s;   3256 sec
[2021-06-06 00:58:00,490 INFO] Step 8900/50000; xent: 2.78; lr: 0.0000267;  31 docs/s;   3274 sec
[2021-06-06 00:58:18,783 INFO] Step 8950/50000; xent: 2.74; lr: 0.0000268;  37 docs/s;   3292 sec
[2021-06-06 00:58:36,945 INFO] Step 9000/50000; xent: 2.76; lr: 0.0000270;  34 docs/s;   3310 sec
[2021-06-06 00:58:55,260 INFO] Step 9050/50000; xent: 2.76; lr: 0.0000271;  33 docs/s;   3329 sec
[2021-06-06 00:59:13,217 INFO] Step 9100/50000; xent: 2.64; lr: 0.0000273;  37 docs/s;   3347 sec
[2021-06-06 00:59:31,572 INFO] Step 9150/50000; xent: 2.92; lr: 0.0000274;  31 docs/s;   3365 sec
[2021-06-06 00:59:49,591 INFO] Step 9200/50000; xent: 2.74; lr: 0.0000276;  36 docs/s;   3383 sec
[2021-06-06 01:00:08,163 INFO] Step 9250/50000; xent: 2.70; lr: 0.0000278;  33 docs/s;   3402 sec
[2021-06-06 01:00:26,069 INFO] Step 9300/50000; xent: 2.86; lr: 0.0000279;  32 docs/s;   3420 sec
[2021-06-06 01:00:44,344 INFO] Step 9350/50000; xent: 2.62; lr: 0.0000280;  36 docs/s;   3438 sec
[2021-06-06 01:01:02,714 INFO] Step 9400/50000; xent: 2.74; lr: 0.0000282;  35 docs/s;   3456 sec
[2021-06-06 01:01:21,081 INFO] Step 9450/50000; xent: 2.85; lr: 0.0000284;  34 docs/s;   3475 sec
[2021-06-06 01:01:39,593 INFO] Step 9500/50000; xent: 2.74; lr: 0.0000285;  34 docs/s;   3493 sec
[2021-06-06 01:01:58,057 INFO] Step 9550/50000; xent: 2.78; lr: 0.0000286;  32 docs/s;   3512 sec
[2021-06-06 01:02:16,500 INFO] Step 9600/50000; xent: 3.10; lr: 0.0000288;  28 docs/s;   3530 sec
[2021-06-06 01:02:34,740 INFO] Step 9650/50000; xent: 2.84; lr: 0.0000289;  32 docs/s;   3548 sec
[2021-06-06 01:02:53,123 INFO] Step 9700/50000; xent: 2.73; lr: 0.0000291;  34 docs/s;   3567 sec
[2021-06-06 01:03:11,734 INFO] Step 9750/50000; xent: 2.70; lr: 0.0000292;  35 docs/s;   3585 sec
[2021-06-06 01:03:30,077 INFO] Step 9800/50000; xent: 2.69; lr: 0.0000294;  34 docs/s;   3604 sec
[2021-06-06 01:03:48,208 INFO] Step 9850/50000; xent: 2.76; lr: 0.0000295;  35 docs/s;   3622 sec
[2021-06-06 01:04:06,232 INFO] Step 9900/50000; xent: 2.87; lr: 0.0000297;  34 docs/s;   3640 sec
[2021-06-06 01:04:24,791 INFO] Step 9950/50000; xent: 2.74; lr: 0.0000298;  34 docs/s;   3658 sec
[2021-06-06 01:04:43,500 INFO] Step 10000/50000; xent: 2.72; lr: 0.0000300;  31 docs/s;   3677 sec
[2021-06-06 01:04:43,502 INFO] Saving checkpoint ../models/bert_ext\model_step_10000.pt
[2021-06-06 01:05:11,717 INFO] Loading train dataset from ../bert_data/train.3.bert.pt, number of examples: 15918
[2021-06-06 01:05:12,173 INFO] Step 10050/50000; xent: 2.72; lr: 0.0000299;  23 docs/s;   3706 sec
[2021-06-06 01:05:30,084 INFO] Step 10100/50000; xent: 2.89; lr: 0.0000299;  28 docs/s;   3724 sec
[2021-06-06 01:05:48,660 INFO] Step 10150/50000; xent: 2.62; lr: 0.0000298;  38 docs/s;   3742 sec
[2021-06-06 01:06:06,993 INFO] Step 10200/50000; xent: 2.72; lr: 0.0000297;  32 docs/s;   3760 sec
[2021-06-06 01:06:25,666 INFO] Step 10250/50000; xent: 3.03; lr: 0.0000296;  29 docs/s;   3779 sec
[2021-06-06 01:06:43,555 INFO] Step 10300/50000; xent: 2.91; lr: 0.0000296;  32 docs/s;   3797 sec
[2021-06-06 01:07:01,941 INFO] Step 10350/50000; xent: 2.94; lr: 0.0000295;  29 docs/s;   3815 sec
[2021-06-06 01:07:20,078 INFO] Step 10400/50000; xent: 2.84; lr: 0.0000294;  32 docs/s;   3834 sec
[2021-06-06 01:07:38,784 INFO] Step 10450/50000; xent: 2.60; lr: 0.0000293;  37 docs/s;   3852 sec
[2021-06-06 01:07:57,031 INFO] Step 10500/50000; xent: 2.96; lr: 0.0000293;  30 docs/s;   3871 sec
[2021-06-06 01:08:15,196 INFO] Step 10550/50000; xent: 2.72; lr: 0.0000292;  33 docs/s;   3889 sec
[2021-06-06 01:08:33,853 INFO] Step 10600/50000; xent: 2.84; lr: 0.0000291;  32 docs/s;   3907 sec
[2021-06-06 01:08:51,669 INFO] Step 10650/50000; xent: 3.05; lr: 0.0000291;  28 docs/s;   3925 sec
[2021-06-06 01:09:10,126 INFO] Step 10700/50000; xent: 2.71; lr: 0.0000290;  36 docs/s;   3944 sec
[2021-06-06 01:09:28,548 INFO] Step 10750/50000; xent: 2.80; lr: 0.0000289;  31 docs/s;   3962 sec
[2021-06-06 01:09:46,834 INFO] Step 10800/50000; xent: 2.96; lr: 0.0000289;  30 docs/s;   3980 sec
[2021-06-06 01:10:05,574 INFO] Step 10850/50000; xent: 2.68; lr: 0.0000288;  35 docs/s;   3999 sec
[2021-06-06 01:10:24,038 INFO] Step 10900/50000; xent: 2.67; lr: 0.0000287;  37 docs/s;   4018 sec
[2021-06-06 01:10:41,709 INFO] Step 10950/50000; xent: 2.60; lr: 0.0000287;  35 docs/s;   4035 sec
[2021-06-06 01:10:59,890 INFO] Step 11000/50000; xent: 2.76; lr: 0.0000286;  31 docs/s;   4053 sec
[2021-06-06 01:11:18,543 INFO] Step 11050/50000; xent: 2.79; lr: 0.0000285;  33 docs/s;   4072 sec
[2021-06-06 01:11:36,840 INFO] Step 11100/50000; xent: 2.93; lr: 0.0000285;  32 docs/s;   4090 sec
[2021-06-06 01:11:55,273 INFO] Step 11150/50000; xent: 2.75; lr: 0.0000284;  31 docs/s;   4109 sec
[2021-06-06 01:12:13,547 INFO] Step 11200/50000; xent: 2.84; lr: 0.0000283;  30 docs/s;   4127 sec
[2021-06-06 01:12:31,832 INFO] Step 11250/50000; xent: 2.72; lr: 0.0000283;  33 docs/s;   4145 sec
[2021-06-06 01:12:50,469 INFO] Step 11300/50000; xent: 2.75; lr: 0.0000282;  34 docs/s;   4164 sec
[2021-06-06 01:13:09,096 INFO] Step 11350/50000; xent: 2.76; lr: 0.0000282;  31 docs/s;   4183 sec
[2021-06-06 01:13:27,519 INFO] Step 11400/50000; xent: 2.76; lr: 0.0000281;  33 docs/s;   4201 sec
[2021-06-06 01:13:45,676 INFO] Step 11450/50000; xent: 2.78; lr: 0.0000280;  32 docs/s;   4219 sec
[2021-06-06 01:14:04,062 INFO] Step 11500/50000; xent: 2.91; lr: 0.0000280;  31 docs/s;   4238 sec
[2021-06-06 01:14:22,368 INFO] Step 11550/50000; xent: 2.68; lr: 0.0000279;  35 docs/s;   4256 sec
[2021-06-06 01:14:41,223 INFO] Step 11600/50000; xent: 3.02; lr: 0.0000279;  30 docs/s;   4275 sec
[2021-06-06 01:14:59,273 INFO] Step 11650/50000; xent: 2.62; lr: 0.0000278;  37 docs/s;   4293 sec
[2021-06-06 01:15:17,504 INFO] Step 11700/50000; xent: 3.20; lr: 0.0000277;  25 docs/s;   4311 sec
[2021-06-06 01:15:35,736 INFO] Step 11750/50000; xent: 2.94; lr: 0.0000277;  32 docs/s;   4329 sec
[2021-06-06 01:15:54,066 INFO] Step 11800/50000; xent: 2.85; lr: 0.0000276;  35 docs/s;   4348 sec
[2021-06-06 01:16:12,155 INFO] Step 11850/50000; xent: 2.64; lr: 0.0000276;  34 docs/s;   4366 sec
[2021-06-06 01:16:30,926 INFO] Step 11900/50000; xent: 2.86; lr: 0.0000275;  32 docs/s;   4384 sec
[2021-06-06 01:16:48,886 INFO] Step 11950/50000; xent: 2.69; lr: 0.0000274;  33 docs/s;   4402 sec
[2021-06-06 01:17:07,292 INFO] Step 12000/50000; xent: 2.83; lr: 0.0000274;  31 docs/s;   4421 sec
[2021-06-06 01:17:25,693 INFO] Step 12050/50000; xent: 2.83; lr: 0.0000273;  34 docs/s;   4439 sec
[2021-06-06 01:17:44,036 INFO] Step 12100/50000; xent: 2.90; lr: 0.0000273;  30 docs/s;   4458 sec
[2021-06-06 01:18:02,278 INFO] Step 12150/50000; xent: 2.72; lr: 0.0000272;  34 docs/s;   4476 sec
[2021-06-06 01:18:20,645 INFO] Step 12200/50000; xent: 2.78; lr: 0.0000272;  32 docs/s;   4494 sec
[2021-06-06 01:18:38,888 INFO] Step 12250/50000; xent: 2.71; lr: 0.0000271;  34 docs/s;   4512 sec
[2021-06-06 01:18:57,524 INFO] Step 12300/50000; xent: 2.68; lr: 0.0000271;  32 docs/s;   4531 sec
[2021-06-06 01:19:15,946 INFO] Step 12350/50000; xent: 2.98; lr: 0.0000270;  33 docs/s;   4549 sec
[2021-06-06 01:19:34,477 INFO] Step 12400/50000; xent: 2.67; lr: 0.0000269;  36 docs/s;   4568 sec
[2021-06-06 01:19:52,962 INFO] Step 12450/50000; xent: 2.79; lr: 0.0000269;  31 docs/s;   4586 sec
[2021-06-06 01:20:11,346 INFO] Step 12500/50000; xent: 2.80; lr: 0.0000268;  34 docs/s;   4605 sec
[2021-06-06 01:20:29,821 INFO] Step 12550/50000; xent: 2.90; lr: 0.0000268;  32 docs/s;   4623 sec
[2021-06-06 01:20:48,710 INFO] Step 12600/50000; xent: 2.58; lr: 0.0000267;  34 docs/s;   4642 sec
[2021-06-06 01:21:06,667 INFO] Step 12650/50000; xent: 2.92; lr: 0.0000267;  32 docs/s;   4660 sec
[2021-06-06 01:21:24,877 INFO] Step 12700/50000; xent: 2.82; lr: 0.0000266;  31 docs/s;   4678 sec
[2021-06-06 01:21:36,020 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-06 01:21:44,911 INFO] Step 12750/50000; xent: 2.83; lr: 0.0000266;  31 docs/s;   4698 sec
[2021-06-06 01:22:03,394 INFO] Step 12800/50000; xent: 2.78; lr: 0.0000265;  32 docs/s;   4717 sec
[2021-06-06 01:22:21,191 INFO] Step 12850/50000; xent: 2.61; lr: 0.0000265;  35 docs/s;   4735 sec
[2021-06-06 01:22:39,571 INFO] Step 12900/50000; xent: 2.70; lr: 0.0000264;  30 docs/s;   4753 sec
[2021-06-06 01:22:57,607 INFO] Step 12950/50000; xent: 2.52; lr: 0.0000264;  36 docs/s;   4771 sec
[2021-06-06 01:23:15,616 INFO] Step 13000/50000; xent: 2.69; lr: 0.0000263;  34 docs/s;   4789 sec
[2021-06-06 01:23:33,459 INFO] Step 13050/50000; xent: 2.58; lr: 0.0000263;  36 docs/s;   4807 sec
[2021-06-06 01:23:51,739 INFO] Step 13100/50000; xent: 2.92; lr: 0.0000262;  30 docs/s;   4825 sec
[2021-06-06 01:24:09,708 INFO] Step 13150/50000; xent: 2.67; lr: 0.0000262;  36 docs/s;   4843 sec
[2021-06-06 01:24:27,837 INFO] Step 13200/50000; xent: 2.53; lr: 0.0000261;  38 docs/s;   4861 sec
[2021-06-06 01:24:46,042 INFO] Step 13250/50000; xent: 2.64; lr: 0.0000261;  37 docs/s;   4880 sec
[2021-06-06 01:25:04,317 INFO] Step 13300/50000; xent: 2.99; lr: 0.0000260;  28 docs/s;   4898 sec
[2021-06-06 01:25:22,464 INFO] Step 13350/50000; xent: 2.63; lr: 0.0000260;  36 docs/s;   4916 sec
[2021-06-06 01:25:40,862 INFO] Step 13400/50000; xent: 2.69; lr: 0.0000259;  32 docs/s;   4934 sec
[2021-06-06 01:25:58,961 INFO] Step 13450/50000; xent: 2.66; lr: 0.0000259;  37 docs/s;   4952 sec
[2021-06-06 01:26:17,315 INFO] Step 13500/50000; xent: 2.54; lr: 0.0000258;  38 docs/s;   4971 sec
[2021-06-06 01:26:35,597 INFO] Step 13550/50000; xent: 2.97; lr: 0.0000258;  30 docs/s;   4989 sec
[2021-06-06 01:26:53,834 INFO] Step 13600/50000; xent: 2.65; lr: 0.0000257;  38 docs/s;   5007 sec
[2021-06-06 01:27:11,907 INFO] Step 13650/50000; xent: 2.68; lr: 0.0000257;  35 docs/s;   5025 sec
[2021-06-06 01:27:30,186 INFO] Step 13700/50000; xent: 2.98; lr: 0.0000256;  28 docs/s;   5044 sec
[2021-06-06 01:27:48,346 INFO] Step 13750/50000; xent: 2.69; lr: 0.0000256;  34 docs/s;   5062 sec
[2021-06-06 01:28:06,617 INFO] Step 13800/50000; xent: 2.75; lr: 0.0000255;  33 docs/s;   5080 sec
[2021-06-06 01:28:24,509 INFO] Step 13850/50000; xent: 2.58; lr: 0.0000255;  34 docs/s;   5098 sec
[2021-06-06 01:28:42,502 INFO] Step 13900/50000; xent: 2.65; lr: 0.0000254;  35 docs/s;   5116 sec
[2021-06-06 01:29:00,691 INFO] Step 13950/50000; xent: 2.64; lr: 0.0000254;  36 docs/s;   5134 sec
[2021-06-06 01:29:18,981 INFO] Step 14000/50000; xent: 2.85; lr: 0.0000254;  32 docs/s;   5152 sec
[2021-06-06 01:29:37,135 INFO] Step 14050/50000; xent: 2.68; lr: 0.0000253;  34 docs/s;   5171 sec
[2021-06-06 01:29:55,015 INFO] Step 14100/50000; xent: 2.68; lr: 0.0000253;  35 docs/s;   5189 sec
[2021-06-06 01:30:13,358 INFO] Step 14150/50000; xent: 2.85; lr: 0.0000252;  30 docs/s;   5207 sec
[2021-06-06 01:30:31,778 INFO] Step 14200/50000; xent: 2.54; lr: 0.0000252;  39 docs/s;   5225 sec
[2021-06-06 01:30:49,716 INFO] Step 14250/50000; xent: 2.63; lr: 0.0000251;  35 docs/s;   5243 sec
[2021-06-06 01:31:08,046 INFO] Step 14300/50000; xent: 2.77; lr: 0.0000251;  33 docs/s;   5262 sec
[2021-06-06 01:31:26,267 INFO] Step 14350/50000; xent: 2.55; lr: 0.0000250;  36 docs/s;   5280 sec
[2021-06-06 01:31:44,278 INFO] Step 14400/50000; xent: 2.75; lr: 0.0000250;  33 docs/s;   5298 sec
[2021-06-06 01:32:02,869 INFO] Step 14450/50000; xent: 2.64; lr: 0.0000250;  32 docs/s;   5316 sec
[2021-06-06 01:32:21,407 INFO] Step 14500/50000; xent: 2.50; lr: 0.0000249;  34 docs/s;   5335 sec
[2021-06-06 01:32:39,899 INFO] Step 14550/50000; xent: 2.95; lr: 0.0000249;  31 docs/s;   5353 sec
[2021-06-06 01:32:58,094 INFO] Step 14600/50000; xent: 2.67; lr: 0.0000248;  36 docs/s;   5372 sec
[2021-06-06 01:33:16,246 INFO] Step 14650/50000; xent: 2.63; lr: 0.0000248;  37 docs/s;   5390 sec
[2021-06-06 01:33:34,621 INFO] Step 14700/50000; xent: 2.74; lr: 0.0000247;  34 docs/s;   5408 sec
[2021-06-06 01:33:53,033 INFO] Step 14750/50000; xent: 2.63; lr: 0.0000247;  35 docs/s;   5427 sec
[2021-06-06 01:34:11,528 INFO] Step 14800/50000; xent: 2.84; lr: 0.0000247;  35 docs/s;   5445 sec
[2021-06-06 01:34:29,928 INFO] Step 14850/50000; xent: 2.49; lr: 0.0000246;  39 docs/s;   5463 sec
[2021-06-06 01:34:47,964 INFO] Step 14900/50000; xent: 2.79; lr: 0.0000246;  34 docs/s;   5481 sec
[2021-06-06 01:35:06,202 INFO] Step 14950/50000; xent: 2.63; lr: 0.0000245;  33 docs/s;   5500 sec
[2021-06-06 01:35:24,710 INFO] Step 15000/50000; xent: 2.92; lr: 0.0000245;  31 docs/s;   5518 sec
[2021-06-06 01:35:24,711 INFO] Saving checkpoint ../models/bert_ext\model_step_15000.pt
[2021-06-06 01:35:49,618 INFO] Step 15050/50000; xent: 2.48; lr: 0.0000245;  29 docs/s;   5543 sec
[2021-06-06 01:36:07,684 INFO] Step 15100/50000; xent: 2.60; lr: 0.0000244;  33 docs/s;   5561 sec
[2021-06-06 01:36:26,007 INFO] Step 15150/50000; xent: 2.97; lr: 0.0000244;  30 docs/s;   5579 sec
[2021-06-06 01:36:44,249 INFO] Step 15200/50000; xent: 2.55; lr: 0.0000243;  38 docs/s;   5598 sec
[2021-06-06 01:37:02,665 INFO] Step 15250/50000; xent: 2.88; lr: 0.0000243;  32 docs/s;   5616 sec
[2021-06-06 01:37:08,344 INFO] Loading train dataset from ../bert_data/train.1.bert.pt, number of examples: 15951
[2021-06-06 01:37:22,559 INFO] Step 15300/50000; xent: 2.54; lr: 0.0000243;  32 docs/s;   5636 sec
[2021-06-06 01:37:40,946 INFO] Step 15350/50000; xent: 2.53; lr: 0.0000242;  34 docs/s;   5654 sec
[2021-06-06 01:37:59,362 INFO] Step 15400/50000; xent: 2.36; lr: 0.0000242;  42 docs/s;   5673 sec
[2021-06-06 01:38:17,847 INFO] Step 15450/50000; xent: 2.81; lr: 0.0000241;  30 docs/s;   5691 sec
[2021-06-06 01:38:36,305 INFO] Step 15500/50000; xent: 2.63; lr: 0.0000241;  33 docs/s;   5710 sec
[2021-06-06 01:38:54,594 INFO] Step 15550/50000; xent: 2.66; lr: 0.0000241;  35 docs/s;   5728 sec
[2021-06-06 01:39:13,094 INFO] Step 15600/50000; xent: 2.64; lr: 0.0000240;  35 docs/s;   5747 sec
[2021-06-06 01:39:31,463 INFO] Step 15650/50000; xent: 2.54; lr: 0.0000240;  35 docs/s;   5765 sec
[2021-06-06 01:39:49,332 INFO] Step 15700/50000; xent: 2.67; lr: 0.0000239;  36 docs/s;   5783 sec
[2021-06-06 01:40:07,378 INFO] Step 15750/50000; xent: 2.63; lr: 0.0000239;  34 docs/s;   5801 sec
[2021-06-06 01:40:25,770 INFO] Step 15800/50000; xent: 2.61; lr: 0.0000239;  36 docs/s;   5819 sec
[2021-06-06 01:40:44,102 INFO] Step 15850/50000; xent: 2.68; lr: 0.0000238;  35 docs/s;   5838 sec
[2021-06-06 01:41:02,581 INFO] Step 15900/50000; xent: 2.48; lr: 0.0000238;  37 docs/s;   5856 sec
[2021-06-06 01:41:20,750 INFO] Step 15950/50000; xent: 2.63; lr: 0.0000238;  34 docs/s;   5874 sec
[2021-06-06 01:41:38,962 INFO] Step 16000/50000; xent: 2.57; lr: 0.0000237;  35 docs/s;   5892 sec
[2021-06-06 01:41:57,320 INFO] Step 16050/50000; xent: 2.83; lr: 0.0000237;  31 docs/s;   5911 sec
[2021-06-06 01:42:15,959 INFO] Step 16100/50000; xent: 2.49; lr: 0.0000236;  40 docs/s;   5929 sec
[2021-06-06 01:42:33,934 INFO] Step 16150/50000; xent: 2.59; lr: 0.0000236;  34 docs/s;   5947 sec
[2021-06-06 01:42:52,208 INFO] Step 16200/50000; xent: 2.71; lr: 0.0000236;  32 docs/s;   5966 sec
[2021-06-06 01:43:10,803 INFO] Step 16250/50000; xent: 2.87; lr: 0.0000235;  29 docs/s;   5984 sec
[2021-06-06 01:43:29,279 INFO] Step 16300/50000; xent: 2.43; lr: 0.0000235;  38 docs/s;   6003 sec
[2021-06-06 01:43:47,578 INFO] Step 16350/50000; xent: 2.40; lr: 0.0000235;  36 docs/s;   6021 sec
[2021-06-06 01:44:06,231 INFO] Step 16400/50000; xent: 2.52; lr: 0.0000234;  32 docs/s;   6040 sec
[2021-06-06 01:44:24,444 INFO] Step 16450/50000; xent: 2.44; lr: 0.0000234;  36 docs/s;   6058 sec
[2021-06-06 01:44:42,831 INFO] Step 16500/50000; xent: 2.63; lr: 0.0000234;  34 docs/s;   6076 sec
[2021-06-06 01:45:01,152 INFO] Step 16550/50000; xent: 2.55; lr: 0.0000233;  35 docs/s;   6095 sec
[2021-06-06 01:45:19,061 INFO] Step 16600/50000; xent: 2.49; lr: 0.0000233;  33 docs/s;   6113 sec
[2021-06-06 01:45:37,448 INFO] Step 16650/50000; xent: 2.39; lr: 0.0000232;  35 docs/s;   6131 sec
[2021-06-06 01:45:55,695 INFO] Step 16700/50000; xent: 2.51; lr: 0.0000232;  33 docs/s;   6149 sec
[2021-06-06 01:46:14,124 INFO] Step 16750/50000; xent: 2.56; lr: 0.0000232;  33 docs/s;   6168 sec
[2021-06-06 01:46:32,398 INFO] Step 16800/50000; xent: 2.46; lr: 0.0000231;  35 docs/s;   6186 sec
[2021-06-06 01:46:50,611 INFO] Step 16850/50000; xent: 2.53; lr: 0.0000231;  33 docs/s;   6204 sec
[2021-06-06 01:47:09,057 INFO] Step 16900/50000; xent: 2.48; lr: 0.0000231;  35 docs/s;   6223 sec
[2021-06-06 01:47:27,561 INFO] Step 16950/50000; xent: 2.34; lr: 0.0000230;  33 docs/s;   6241 sec
[2021-06-06 01:47:46,028 INFO] Step 17000/50000; xent: 2.43; lr: 0.0000230;  33 docs/s;   6260 sec
[2021-06-06 01:48:04,523 INFO] Step 17050/50000; xent: 2.28; lr: 0.0000230;  36 docs/s;   6278 sec
[2021-06-06 01:48:23,133 INFO] Step 17100/50000; xent: 2.49; lr: 0.0000229;  35 docs/s;   6297 sec
[2021-06-06 01:48:41,113 INFO] Step 17150/50000; xent: 2.31; lr: 0.0000229;  38 docs/s;   6315 sec
[2021-06-06 01:48:59,442 INFO] Step 17200/50000; xent: 2.53; lr: 0.0000229;  30 docs/s;   6333 sec
[2021-06-06 01:49:17,448 INFO] Step 17250/50000; xent: 2.22; lr: 0.0000228;  38 docs/s;   6351 sec
[2021-06-06 01:49:36,167 INFO] Step 17300/50000; xent: 2.46; lr: 0.0000228;  35 docs/s;   6370 sec
[2021-06-06 01:49:54,356 INFO] Step 17350/50000; xent: 2.48; lr: 0.0000228;  30 docs/s;   6388 sec
[2021-06-06 01:50:12,283 INFO] Step 17400/50000; xent: 2.34; lr: 0.0000227;  35 docs/s;   6406 sec
[2021-06-06 01:50:30,650 INFO] Step 17450/50000; xent: 2.49; lr: 0.0000227;  33 docs/s;   6424 sec
[2021-06-06 01:50:49,109 INFO] Step 17500/50000; xent: 2.31; lr: 0.0000227;  37 docs/s;   6443 sec
[2021-06-06 01:51:07,321 INFO] Step 17550/50000; xent: 2.40; lr: 0.0000226;  36 docs/s;   6461 sec
[2021-06-06 01:51:25,584 INFO] Step 17600/50000; xent: 2.33; lr: 0.0000226;  35 docs/s;   6479 sec
[2021-06-06 01:51:43,953 INFO] Step 17650/50000; xent: 2.12; lr: 0.0000226;  40 docs/s;   6497 sec
[2021-06-06 01:52:02,669 INFO] Step 17700/50000; xent: 2.58; lr: 0.0000225;  32 docs/s;   6516 sec
[2021-06-06 01:52:20,984 INFO] Step 17750/50000; xent: 2.26; lr: 0.0000225;  36 docs/s;   6534 sec
[2021-06-06 01:52:32,745 INFO] Loading train dataset from ../bert_data/train.2.bert.pt, number of examples: 15944
[2021-06-06 01:52:41,197 INFO] Step 17800/50000; xent: 2.35; lr: 0.0000225;  31 docs/s;   6555 sec
[2021-06-06 01:52:59,625 INFO] Step 17850/50000; xent: 2.26; lr: 0.0000225;  37 docs/s;   6573 sec
[2021-06-06 01:53:18,117 INFO] Step 17900/50000; xent: 2.53; lr: 0.0000224;  35 docs/s;   6592 sec
[2021-06-06 01:53:36,825 INFO] Step 17950/50000; xent: 2.34; lr: 0.0000224;  34 docs/s;   6610 sec
[2021-06-06 01:53:55,298 INFO] Step 18000/50000; xent: 2.25; lr: 0.0000224;  36 docs/s;   6629 sec
[2021-06-06 01:54:13,569 INFO] Step 18050/50000; xent: 2.29; lr: 0.0000223;  35 docs/s;   6647 sec
[2021-06-06 01:54:31,628 INFO] Step 18100/50000; xent: 2.54; lr: 0.0000223;  33 docs/s;   6665 sec
[2021-06-06 01:54:49,925 INFO] Step 18150/50000; xent: 2.37; lr: 0.0000223;  35 docs/s;   6683 sec
[2021-06-06 01:55:08,499 INFO] Step 18200/50000; xent: 2.39; lr: 0.0000222;  36 docs/s;   6702 sec
[2021-06-06 01:55:26,772 INFO] Step 18250/50000; xent: 2.39; lr: 0.0000222;  35 docs/s;   6720 sec
[2021-06-06 01:55:44,840 INFO] Step 18300/50000; xent: 2.43; lr: 0.0000222;  35 docs/s;   6738 sec
[2021-06-06 01:56:03,196 INFO] Step 18350/50000; xent: 2.31; lr: 0.0000221;  36 docs/s;   6757 sec
[2021-06-06 01:56:21,529 INFO] Step 18400/50000; xent: 2.33; lr: 0.0000221;  34 docs/s;   6775 sec
[2021-06-06 01:56:40,076 INFO] Step 18450/50000; xent: 2.16; lr: 0.0000221;  38 docs/s;   6794 sec
[2021-06-06 01:56:58,378 INFO] Step 18500/50000; xent: 2.56; lr: 0.0000221;  31 docs/s;   6812 sec
[2021-06-06 01:57:16,689 INFO] Step 18550/50000; xent: 2.21; lr: 0.0000220;  39 docs/s;   6830 sec
[2021-06-06 01:57:35,187 INFO] Step 18600/50000; xent: 2.27; lr: 0.0000220;  37 docs/s;   6849 sec
[2021-06-06 01:57:53,635 INFO] Step 18650/50000; xent: 2.58; lr: 0.0000220;  32 docs/s;   6867 sec
[2021-06-06 01:58:12,120 INFO] Step 18700/50000; xent: 2.33; lr: 0.0000219;  34 docs/s;   6886 sec
[2021-06-06 01:58:30,349 INFO] Step 18750/50000; xent: 2.42; lr: 0.0000219;  34 docs/s;   6904 sec
[2021-06-06 01:58:48,747 INFO] Step 18800/50000; xent: 2.36; lr: 0.0000219;  36 docs/s;   6922 sec
[2021-06-06 01:59:06,992 INFO] Step 18850/50000; xent: 2.41; lr: 0.0000219;  37 docs/s;   6940 sec
[2021-06-06 01:59:25,135 INFO] Step 18900/50000; xent: 2.41; lr: 0.0000218;  34 docs/s;   6959 sec
[2021-06-06 01:59:43,508 INFO] Step 18950/50000; xent: 2.32; lr: 0.0000218;  37 docs/s;   6977 sec
[2021-06-06 02:00:01,555 INFO] Step 19000/50000; xent: 2.16; lr: 0.0000218;  37 docs/s;   6995 sec
[2021-06-06 02:00:20,173 INFO] Step 19050/50000; xent: 2.26; lr: 0.0000217;  34 docs/s;   7014 sec
[2021-06-06 02:00:38,724 INFO] Step 19100/50000; xent: 2.30; lr: 0.0000217;  36 docs/s;   7032 sec
[2021-06-06 02:00:56,847 INFO] Step 19150/50000; xent: 2.14; lr: 0.0000217;  38 docs/s;   7050 sec
[2021-06-06 02:01:15,691 INFO] Step 19200/50000; xent: 2.35; lr: 0.0000217;  34 docs/s;   7069 sec
[2021-06-06 02:01:34,145 INFO] Step 19250/50000; xent: 2.28; lr: 0.0000216;  35 docs/s;   7088 sec
[2021-06-06 02:01:52,421 INFO] Step 19300/50000; xent: 2.39; lr: 0.0000216;  33 docs/s;   7106 sec
[2021-06-06 02:02:10,626 INFO] Step 19350/50000; xent: 2.37; lr: 0.0000216;  34 docs/s;   7124 sec
[2021-06-06 02:02:29,113 INFO] Step 19400/50000; xent: 2.46; lr: 0.0000215;  30 docs/s;   7143 sec
[2021-06-06 02:02:47,700 INFO] Step 19450/50000; xent: 2.39; lr: 0.0000215;  32 docs/s;   7161 sec
[2021-06-06 02:03:06,246 INFO] Step 19500/50000; xent: 2.26; lr: 0.0000215;  35 docs/s;   7180 sec
[2021-06-06 02:03:24,772 INFO] Step 19550/50000; xent: 2.36; lr: 0.0000215;  35 docs/s;   7198 sec
[2021-06-06 02:03:43,077 INFO] Step 19600/50000; xent: 2.27; lr: 0.0000214;  38 docs/s;   7217 sec
[2021-06-06 02:04:01,473 INFO] Step 19650/50000; xent: 2.23; lr: 0.0000214;  39 docs/s;   7235 sec
[2021-06-06 02:04:19,776 INFO] Step 19700/50000; xent: 2.40; lr: 0.0000214;  36 docs/s;   7253 sec
[2021-06-06 02:04:38,197 INFO] Step 19750/50000; xent: 2.32; lr: 0.0000213;  36 docs/s;   7272 sec
[2021-06-06 02:04:56,460 INFO] Step 19800/50000; xent: 2.36; lr: 0.0000213;  36 docs/s;   7290 sec
[2021-06-06 02:05:14,973 INFO] Step 19850/50000; xent: 2.37; lr: 0.0000213;  34 docs/s;   7308 sec
[2021-06-06 02:05:33,357 INFO] Step 19900/50000; xent: 2.31; lr: 0.0000213;  35 docs/s;   7327 sec
[2021-06-06 02:05:51,878 INFO] Step 19950/50000; xent: 2.02; lr: 0.0000212;  42 docs/s;   7345 sec
[2021-06-06 02:06:09,949 INFO] Step 20000/50000; xent: 2.74; lr: 0.0000212;  29 docs/s;   7363 sec
[2021-06-06 02:06:09,951 INFO] Saving checkpoint ../models/bert_ext\model_step_20000.pt
[2021-06-06 02:06:33,350 INFO] Step 20050/50000; xent: 2.20; lr: 0.0000212;  31 docs/s;   7387 sec
[2021-06-06 02:06:51,531 INFO] Step 20100/50000; xent: 2.33; lr: 0.0000212;  35 docs/s;   7405 sec
[2021-06-06 02:07:09,780 INFO] Step 20150/50000; xent: 2.33; lr: 0.0000211;  35 docs/s;   7423 sec
[2021-06-06 02:07:28,084 INFO] Step 20200/50000; xent: 2.35; lr: 0.0000211;  33 docs/s;   7442 sec
[2021-06-06 02:07:44,195 INFO] Loading train dataset from ../bert_data/train.4.bert.pt, number of examples: 15873
[2021-06-06 02:07:48,151 INFO] Step 20250/50000; xent: 2.37; lr: 0.0000211;  33 docs/s;   7462 sec
[2021-06-06 02:08:06,522 INFO] Step 20300/50000; xent: 2.54; lr: 0.0000211;  33 docs/s;   7480 sec
[2021-06-06 02:08:24,954 INFO] Step 20350/50000; xent: 2.35; lr: 0.0000210;  33 docs/s;   7498 sec
[2021-06-06 02:08:43,385 INFO] Step 20400/50000; xent: 2.45; lr: 0.0000210;  30 docs/s;   7517 sec
[2021-06-06 02:09:01,570 INFO] Step 20450/50000; xent: 2.17; lr: 0.0000210;  38 docs/s;   7535 sec
[2021-06-06 02:09:19,904 INFO] Step 20500/50000; xent: 2.36; lr: 0.0000210;  32 docs/s;   7553 sec
[2021-06-06 02:09:38,172 INFO] Step 20550/50000; xent: 2.36; lr: 0.0000209;  32 docs/s;   7572 sec
[2021-06-06 02:09:56,025 INFO] Step 20600/50000; xent: 2.39; lr: 0.0000209;  35 docs/s;   7590 sec
[2021-06-06 02:10:14,332 INFO] Step 20650/50000; xent: 2.17; lr: 0.0000209;  37 docs/s;   7608 sec
[2021-06-06 02:10:32,905 INFO] Step 20700/50000; xent: 2.31; lr: 0.0000209;  32 docs/s;   7626 sec
[2021-06-06 02:10:51,148 INFO] Step 20750/50000; xent: 2.19; lr: 0.0000208;  37 docs/s;   7645 sec
[2021-06-06 02:11:09,692 INFO] Step 20800/50000; xent: 2.14; lr: 0.0000208;  39 docs/s;   7663 sec
[2021-06-06 02:11:28,156 INFO] Step 20850/50000; xent: 2.58; lr: 0.0000208;  29 docs/s;   7682 sec
[2021-06-06 02:11:46,789 INFO] Step 20900/50000; xent: 2.55; lr: 0.0000208;  29 docs/s;   7700 sec
[2021-06-06 02:12:05,021 INFO] Step 20950/50000; xent: 2.30; lr: 0.0000207;  35 docs/s;   7719 sec
[2021-06-06 02:12:23,582 INFO] Step 21000/50000; xent: 2.81; lr: 0.0000207;  27 docs/s;   7737 sec
[2021-06-06 02:12:41,895 INFO] Step 21050/50000; xent: 2.45; lr: 0.0000207;  33 docs/s;   7755 sec
[2021-06-06 02:12:59,946 INFO] Step 21100/50000; xent: 2.15; lr: 0.0000207;  37 docs/s;   7773 sec
[2021-06-06 02:13:18,409 INFO] Step 21150/50000; xent: 2.28; lr: 0.0000206;  37 docs/s;   7792 sec
[2021-06-06 02:13:36,743 INFO] Step 21200/50000; xent: 2.43; lr: 0.0000206;  32 docs/s;   7810 sec
[2021-06-06 02:13:55,189 INFO] Step 21250/50000; xent: 2.10; lr: 0.0000206;  38 docs/s;   7829 sec
[2021-06-06 02:14:13,572 INFO] Step 21300/50000; xent: 2.37; lr: 0.0000206;  32 docs/s;   7847 sec
[2021-06-06 02:14:31,790 INFO] Step 21350/50000; xent: 2.35; lr: 0.0000205;  35 docs/s;   7865 sec
[2021-06-06 02:14:50,320 INFO] Step 21400/50000; xent: 2.36; lr: 0.0000205;  32 docs/s;   7884 sec
[2021-06-06 02:15:08,821 INFO] Step 21450/50000; xent: 2.24; lr: 0.0000205;  37 docs/s;   7902 sec
[2021-06-06 02:15:27,237 INFO] Step 21500/50000; xent: 2.29; lr: 0.0000205;  35 docs/s;   7921 sec
[2021-06-06 02:15:45,495 INFO] Step 21550/50000; xent: 2.34; lr: 0.0000204;  34 docs/s;   7939 sec
[2021-06-06 02:16:04,012 INFO] Step 21600/50000; xent: 2.30; lr: 0.0000204;  35 docs/s;   7957 sec
[2021-06-06 02:16:22,384 INFO] Step 21650/50000; xent: 2.55; lr: 0.0000204;  30 docs/s;   7976 sec
[2021-06-06 02:16:40,656 INFO] Step 21700/50000; xent: 2.29; lr: 0.0000204;  37 docs/s;   7994 sec
[2021-06-06 02:16:58,909 INFO] Step 21750/50000; xent: 2.37; lr: 0.0000203;  34 docs/s;   8012 sec
[2021-06-06 02:17:17,569 INFO] Step 21800/50000; xent: 2.41; lr: 0.0000203;  35 docs/s;   8031 sec
[2021-06-06 02:17:36,101 INFO] Step 21850/50000; xent: 2.41; lr: 0.0000203;  35 docs/s;   8050 sec
[2021-06-06 02:17:54,667 INFO] Step 21900/50000; xent: 2.22; lr: 0.0000203;  37 docs/s;   8068 sec
[2021-06-06 02:18:12,925 INFO] Step 21950/50000; xent: 2.45; lr: 0.0000202;  31 docs/s;   8086 sec
[2021-06-06 02:18:31,304 INFO] Step 22000/50000; xent: 2.38; lr: 0.0000202;  35 docs/s;   8105 sec
[2021-06-06 02:18:49,762 INFO] Step 22050/50000; xent: 2.41; lr: 0.0000202;  31 docs/s;   8123 sec
[2021-06-06 02:19:08,205 INFO] Step 22100/50000; xent: 2.25; lr: 0.0000202;  35 docs/s;   8142 sec
[2021-06-06 02:19:26,825 INFO] Step 22150/50000; xent: 2.37; lr: 0.0000202;  34 docs/s;   8160 sec
[2021-06-06 02:19:44,829 INFO] Step 22200/50000; xent: 2.25; lr: 0.0000201;  36 docs/s;   8178 sec
[2021-06-06 02:20:03,239 INFO] Step 22250/50000; xent: 2.53; lr: 0.0000201;  32 docs/s;   8197 sec
[2021-06-06 02:20:21,836 INFO] Step 22300/50000; xent: 2.30; lr: 0.0000201;  36 docs/s;   8215 sec
[2021-06-06 02:20:40,115 INFO] Step 22350/50000; xent: 2.42; lr: 0.0000201;  32 docs/s;   8234 sec
[2021-06-06 02:20:58,284 INFO] Step 22400/50000; xent: 2.20; lr: 0.0000200;  36 docs/s;   8252 sec
[2021-06-06 02:21:16,649 INFO] Step 22450/50000; xent: 2.40; lr: 0.0000200;  32 docs/s;   8270 sec
[2021-06-06 02:21:34,962 INFO] Step 22500/50000; xent: 2.15; lr: 0.0000200;  39 docs/s;   8288 sec
[2021-06-06 02:21:53,601 INFO] Step 22550/50000; xent: 2.57; lr: 0.0000200;  29 docs/s;   8307 sec
[2021-06-06 02:22:11,976 INFO] Step 22600/50000; xent: 2.32; lr: 0.0000200;  35 docs/s;   8325 sec
[2021-06-06 02:22:30,410 INFO] Step 22650/50000; xent: 2.30; lr: 0.0000199;  37 docs/s;   8344 sec
[2021-06-06 02:22:48,781 INFO] Step 22700/50000; xent: 2.35; lr: 0.0000199;  32 docs/s;   8362 sec
[2021-06-06 02:23:07,278 INFO] Step 22750/50000; xent: 2.19; lr: 0.0000199;  35 docs/s;   8381 sec
[2021-06-06 02:23:19,127 INFO] Loading train dataset from ../bert_data/train.3.bert.pt, number of examples: 15918
[2021-06-06 02:23:27,243 INFO] Step 22800/50000; xent: 2.42; lr: 0.0000199;  27 docs/s;   8401 sec
[2021-06-06 02:23:45,759 INFO] Step 22850/50000; xent: 2.29; lr: 0.0000198;  37 docs/s;   8419 sec
[2021-06-06 02:24:04,503 INFO] Step 22900/50000; xent: 2.39; lr: 0.0000198;  32 docs/s;   8438 sec
[2021-06-06 02:24:23,256 INFO] Step 22950/50000; xent: 2.38; lr: 0.0000198;  31 docs/s;   8457 sec
[2021-06-06 02:24:41,438 INFO] Step 23000/50000; xent: 2.45; lr: 0.0000198;  31 docs/s;   8475 sec
[2021-06-06 02:24:59,687 INFO] Step 23050/50000; xent: 2.23; lr: 0.0000198;  37 docs/s;   8493 sec
[2021-06-06 02:25:18,076 INFO] Step 23100/50000; xent: 2.40; lr: 0.0000197;  34 docs/s;   8512 sec
[2021-06-06 02:25:36,469 INFO] Step 23150/50000; xent: 2.48; lr: 0.0000197;  31 docs/s;   8530 sec
[2021-06-06 02:25:54,857 INFO] Step 23200/50000; xent: 2.36; lr: 0.0000197;  30 docs/s;   8548 sec
[2021-06-06 02:26:13,357 INFO] Step 23250/50000; xent: 2.40; lr: 0.0000197;  33 docs/s;   8567 sec
[2021-06-06 02:26:31,755 INFO] Step 23300/50000; xent: 2.44; lr: 0.0000197;  30 docs/s;   8585 sec
[2021-06-06 02:26:50,236 INFO] Step 23350/50000; xent: 2.24; lr: 0.0000196;  35 docs/s;   8604 sec
[2021-06-06 02:27:08,279 INFO] Step 23400/50000; xent: 2.25; lr: 0.0000196;  36 docs/s;   8622 sec
[2021-06-06 02:27:26,284 INFO] Step 23450/50000; xent: 2.51; lr: 0.0000196;  28 docs/s;   8640 sec
[2021-06-06 02:27:44,423 INFO] Step 23500/50000; xent: 2.50; lr: 0.0000196;  29 docs/s;   8658 sec
[2021-06-06 02:28:02,730 INFO] Step 23550/50000; xent: 2.26; lr: 0.0000195;  36 docs/s;   8676 sec
[2021-06-06 02:28:21,260 INFO] Step 23600/50000; xent: 2.17; lr: 0.0000195;  32 docs/s;   8695 sec
[2021-06-06 02:28:39,553 INFO] Step 23650/50000; xent: 2.44; lr: 0.0000195;  32 docs/s;   8713 sec
[2021-06-06 02:28:57,869 INFO] Step 23700/50000; xent: 2.26; lr: 0.0000195;  35 docs/s;   8731 sec
[2021-06-06 02:29:16,511 INFO] Step 23750/50000; xent: 2.24; lr: 0.0000195;  37 docs/s;   8750 sec
[2021-06-06 02:29:34,974 INFO] Step 23800/50000; xent: 2.58; lr: 0.0000194;  28 docs/s;   8768 sec
[2021-06-06 02:29:53,596 INFO] Step 23850/50000; xent: 2.30; lr: 0.0000194;  34 docs/s;   8787 sec
[2021-06-06 02:30:11,876 INFO] Step 23900/50000; xent: 2.45; lr: 0.0000194;  31 docs/s;   8805 sec
[2021-06-06 02:30:30,232 INFO] Step 23950/50000; xent: 2.35; lr: 0.0000194;  33 docs/s;   8824 sec
[2021-06-06 02:30:48,515 INFO] Step 24000/50000; xent: 2.50; lr: 0.0000194;  32 docs/s;   8842 sec
[2021-06-06 02:31:06,671 INFO] Step 24050/50000; xent: 2.44; lr: 0.0000193;  32 docs/s;   8860 sec
[2021-06-06 02:31:25,074 INFO] Step 24100/50000; xent: 2.21; lr: 0.0000193;  33 docs/s;   8879 sec
[2021-06-06 02:31:43,507 INFO] Step 24150/50000; xent: 2.52; lr: 0.0000193;  28 docs/s;   8897 sec
[2021-06-06 02:32:01,779 INFO] Step 24200/50000; xent: 2.26; lr: 0.0000193;  34 docs/s;   8915 sec
[2021-06-06 02:32:20,037 INFO] Step 24250/50000; xent: 2.41; lr: 0.0000193;  31 docs/s;   8934 sec
[2021-06-06 02:32:38,637 INFO] Step 24300/50000; xent: 2.44; lr: 0.0000192;  33 docs/s;   8952 sec
[2021-06-06 02:32:56,958 INFO] Step 24350/50000; xent: 2.22; lr: 0.0000192;  34 docs/s;   8970 sec
[2021-06-06 02:33:15,142 INFO] Step 24400/50000; xent: 2.23; lr: 0.0000192;  35 docs/s;   8989 sec
[2021-06-06 02:33:33,324 INFO] Step 24450/50000; xent: 2.38; lr: 0.0000192;  35 docs/s;   9007 sec
[2021-06-06 02:33:51,528 INFO] Step 24500/50000; xent: 2.52; lr: 0.0000192;  30 docs/s;   9025 sec
[2021-06-06 02:34:09,973 INFO] Step 24550/50000; xent: 2.38; lr: 0.0000191;  34 docs/s;   9043 sec
[2021-06-06 02:34:28,376 INFO] Step 24600/50000; xent: 2.36; lr: 0.0000191;  32 docs/s;   9062 sec
[2021-06-06 02:34:46,883 INFO] Step 24650/50000; xent: 2.20; lr: 0.0000191;  36 docs/s;   9080 sec
[2021-06-06 02:35:04,852 INFO] Step 24700/50000; xent: 2.60; lr: 0.0000191;  29 docs/s;   9098 sec
[2021-06-06 02:35:23,215 INFO] Step 24750/50000; xent: 2.29; lr: 0.0000191;  34 docs/s;   9117 sec
[2021-06-06 02:35:41,433 INFO] Step 24800/50000; xent: 2.28; lr: 0.0000191;  32 docs/s;   9135 sec
[2021-06-06 02:35:59,997 INFO] Step 24850/50000; xent: 2.48; lr: 0.0000190;  30 docs/s;   9153 sec
[2021-06-06 02:36:18,122 INFO] Step 24900/50000; xent: 2.31; lr: 0.0000190;  32 docs/s;   9172 sec
[2021-06-06 02:36:36,811 INFO] Step 24950/50000; xent: 2.60; lr: 0.0000190;  30 docs/s;   9190 sec
[2021-06-06 02:36:55,390 INFO] Step 25000/50000; xent: 2.30; lr: 0.0000190;  33 docs/s;   9209 sec
[2021-06-06 02:36:55,392 INFO] Saving checkpoint ../models/bert_ext\model_step_25000.pt
[2021-06-06 02:37:20,948 INFO] Step 25050/50000; xent: 2.34; lr: 0.0000190;  25 docs/s;   9234 sec
[2021-06-06 02:37:39,142 INFO] Step 25100/50000; xent: 2.30; lr: 0.0000189;  32 docs/s;   9253 sec
[2021-06-06 02:37:57,833 INFO] Step 25150/50000; xent: 2.53; lr: 0.0000189;  31 docs/s;   9271 sec
[2021-06-06 02:38:16,189 INFO] Step 25200/50000; xent: 2.69; lr: 0.0000189;  29 docs/s;   9290 sec
[2021-06-06 02:38:34,228 INFO] Step 25250/50000; xent: 2.35; lr: 0.0000189;  33 docs/s;   9308 sec
[2021-06-06 02:38:52,777 INFO] Step 25300/50000; xent: 2.27; lr: 0.0000189;  34 docs/s;   9326 sec
[2021-06-06 02:39:11,108 INFO] Step 25350/50000; xent: 2.32; lr: 0.0000188;  32 docs/s;   9345 sec
[2021-06-06 02:39:29,545 INFO] Step 25400/50000; xent: 2.35; lr: 0.0000188;  34 docs/s;   9363 sec
[2021-06-06 02:39:48,235 INFO] Step 25450/50000; xent: 2.50; lr: 0.0000188;  29 docs/s;   9382 sec
[2021-06-06 02:39:51,312 INFO] Loading train dataset from ../bert_data/train.4.bert.pt, number of examples: 15873
[2021-06-06 02:40:08,462 INFO] Step 25500/50000; xent: 2.07; lr: 0.0000188;  33 docs/s;   9402 sec
[2021-06-06 02:40:26,643 INFO] Step 25550/50000; xent: 2.10; lr: 0.0000188;  36 docs/s;   9420 sec
[2021-06-06 02:40:45,090 INFO] Step 25600/50000; xent: 2.36; lr: 0.0000188;  31 docs/s;   9439 sec
[2021-06-06 02:41:03,572 INFO] Step 25650/50000; xent: 2.24; lr: 0.0000187;  31 docs/s;   9457 sec
[2021-06-06 02:41:22,012 INFO] Step 25700/50000; xent: 2.24; lr: 0.0000187;  34 docs/s;   9475 sec
[2021-06-06 02:41:40,161 INFO] Step 25750/50000; xent: 2.12; lr: 0.0000187;  36 docs/s;   9494 sec
[2021-06-06 02:41:58,395 INFO] Step 25800/50000; xent: 2.06; lr: 0.0000187;  37 docs/s;   9512 sec
[2021-06-06 02:42:16,617 INFO] Step 25850/50000; xent: 2.44; lr: 0.0000187;  29 docs/s;   9530 sec
[2021-06-06 02:42:35,081 INFO] Step 25900/50000; xent: 2.05; lr: 0.0000186;  37 docs/s;   9549 sec
[2021-06-06 02:42:53,750 INFO] Step 25950/50000; xent: 2.07; lr: 0.0000186;  34 docs/s;   9567 sec
[2021-06-06 02:43:12,313 INFO] Step 26000/50000; xent: 2.20; lr: 0.0000186;  34 docs/s;   9586 sec
[2021-06-06 02:43:30,775 INFO] Step 26050/50000; xent: 2.33; lr: 0.0000186;  31 docs/s;   9604 sec
[2021-06-06 02:43:48,956 INFO] Step 26100/50000; xent: 2.11; lr: 0.0000186;  35 docs/s;   9622 sec
[2021-06-06 02:44:07,101 INFO] Step 26150/50000; xent: 2.47; lr: 0.0000186;  29 docs/s;   9641 sec
[2021-06-06 02:44:25,520 INFO] Step 26200/50000; xent: 2.02; lr: 0.0000185;  38 docs/s;   9659 sec
[2021-06-06 02:44:43,669 INFO] Step 26250/50000; xent: 2.24; lr: 0.0000185;  34 docs/s;   9677 sec
[2021-06-06 02:45:02,249 INFO] Step 26300/50000; xent: 2.30; lr: 0.0000185;  34 docs/s;   9696 sec
[2021-06-06 02:45:20,564 INFO] Step 26350/50000; xent: 2.11; lr: 0.0000185;  37 docs/s;   9714 sec
[2021-06-06 02:45:39,037 INFO] Step 26400/50000; xent: 2.08; lr: 0.0000185;  36 docs/s;   9733 sec
[2021-06-06 02:45:57,406 INFO] Step 26450/50000; xent: 1.99; lr: 0.0000184;  38 docs/s;   9751 sec
[2021-06-06 02:46:15,702 INFO] Step 26500/50000; xent: 2.15; lr: 0.0000184;  34 docs/s;   9769 sec
[2021-06-06 02:46:33,983 INFO] Step 26550/50000; xent: 2.34; lr: 0.0000184;  31 docs/s;   9787 sec
[2021-06-06 02:46:52,596 INFO] Step 26600/50000; xent: 2.19; lr: 0.0000184;  33 docs/s;   9806 sec
[2021-06-06 02:47:10,811 INFO] Step 26650/50000; xent: 2.13; lr: 0.0000184;  34 docs/s;   9824 sec
[2021-06-06 02:47:29,100 INFO] Step 26700/50000; xent: 2.13; lr: 0.0000184;  35 docs/s;   9843 sec
[2021-06-06 02:47:47,669 INFO] Step 26750/50000; xent: 1.90; lr: 0.0000183;  37 docs/s;   9861 sec
[2021-06-06 02:48:05,838 INFO] Step 26800/50000; xent: 2.03; lr: 0.0000183;  40 docs/s;   9879 sec
[2021-06-06 02:48:23,956 INFO] Step 26850/50000; xent: 2.21; lr: 0.0000183;  35 docs/s;   9897 sec
[2021-06-06 02:48:42,701 INFO] Step 26900/50000; xent: 2.21; lr: 0.0000183;  33 docs/s;   9916 sec
[2021-06-06 02:49:01,197 INFO] Step 26950/50000; xent: 2.37; lr: 0.0000183;  28 docs/s;   9935 sec
[2021-06-06 02:49:19,261 INFO] Step 27000/50000; xent: 2.20; lr: 0.0000183;  36 docs/s;   9953 sec
[2021-06-06 02:49:37,741 INFO] Step 27050/50000; xent: 2.08; lr: 0.0000182;  36 docs/s;   9971 sec
[2021-06-06 02:49:55,664 INFO] Step 27100/50000; xent: 2.24; lr: 0.0000182;  35 docs/s;   9989 sec
[2021-06-06 02:50:14,097 INFO] Step 27150/50000; xent: 2.17; lr: 0.0000182;  32 docs/s;  10008 sec
[2021-06-06 02:50:32,301 INFO] Step 27200/50000; xent: 2.29; lr: 0.0000182;  34 docs/s;  10026 sec
[2021-06-06 02:50:50,770 INFO] Step 27250/50000; xent: 2.20; lr: 0.0000182;  33 docs/s;  10044 sec
[2021-06-06 02:51:09,201 INFO] Step 27300/50000; xent: 2.26; lr: 0.0000182;  33 docs/s;  10063 sec
[2021-06-06 02:51:27,140 INFO] Step 27350/50000; xent: 1.99; lr: 0.0000181;  40 docs/s;  10081 sec
[2021-06-06 02:51:45,616 INFO] Step 27400/50000; xent: 2.31; lr: 0.0000181;  32 docs/s;  10099 sec
[2021-06-06 02:52:04,000 INFO] Step 27450/50000; xent: 2.24; lr: 0.0000181;  34 docs/s;  10117 sec
[2021-06-06 02:52:22,378 INFO] Step 27500/50000; xent: 2.30; lr: 0.0000181;  32 docs/s;  10136 sec
[2021-06-06 02:52:40,558 INFO] Step 27550/50000; xent: 2.25; lr: 0.0000181;  34 docs/s;  10154 sec
[2021-06-06 02:52:58,674 INFO] Step 27600/50000; xent: 2.06; lr: 0.0000181;  35 docs/s;  10172 sec
[2021-06-06 02:53:17,126 INFO] Step 27650/50000; xent: 2.08; lr: 0.0000180;  34 docs/s;  10191 sec
[2021-06-06 02:53:35,578 INFO] Step 27700/50000; xent: 2.24; lr: 0.0000180;  33 docs/s;  10209 sec
[2021-06-06 02:53:53,956 INFO] Step 27750/50000; xent: 2.25; lr: 0.0000180;  33 docs/s;  10227 sec
[2021-06-06 02:54:12,390 INFO] Step 27800/50000; xent: 2.13; lr: 0.0000180;  36 docs/s;  10246 sec
[2021-06-06 02:54:30,497 INFO] Step 27850/50000; xent: 2.22; lr: 0.0000180;  32 docs/s;  10264 sec
[2021-06-06 02:54:48,981 INFO] Step 27900/50000; xent: 2.26; lr: 0.0000180;  31 docs/s;  10282 sec
[2021-06-06 02:55:07,393 INFO] Step 27950/50000; xent: 2.14; lr: 0.0000179;  33 docs/s;  10301 sec
[2021-06-06 02:55:24,717 INFO] Loading train dataset from ../bert_data/train.2.bert.pt, number of examples: 15944
[2021-06-06 02:55:27,383 INFO] Step 28000/50000; xent: 2.10; lr: 0.0000179;  33 docs/s;  10321 sec
[2021-06-06 02:55:46,241 INFO] Step 28050/50000; xent: 2.35; lr: 0.0000179;  31 docs/s;  10340 sec
[2021-06-06 02:56:04,662 INFO] Step 28100/50000; xent: 2.23; lr: 0.0000179;  36 docs/s;  10358 sec
[2021-06-06 02:56:22,991 INFO] Step 28150/50000; xent: 2.08; lr: 0.0000179;  38 docs/s;  10376 sec
[2021-06-06 02:56:41,596 INFO] Step 28200/50000; xent: 2.17; lr: 0.0000179;  36 docs/s;  10395 sec
[2021-06-06 02:56:59,778 INFO] Step 28250/50000; xent: 2.12; lr: 0.0000178;  39 docs/s;  10413 sec
[2021-06-06 02:57:18,029 INFO] Step 28300/50000; xent: 2.31; lr: 0.0000178;  35 docs/s;  10432 sec
[2021-06-06 02:57:36,191 INFO] Step 28350/50000; xent: 2.07; lr: 0.0000178;  32 docs/s;  10450 sec
[2021-06-06 02:57:54,706 INFO] Step 28400/50000; xent: 2.08; lr: 0.0000178;  36 docs/s;  10468 sec
[2021-06-06 02:58:13,058 INFO] Step 28450/50000; xent: 2.12; lr: 0.0000178;  36 docs/s;  10487 sec
[2021-06-06 02:58:31,383 INFO] Step 28500/50000; xent: 2.28; lr: 0.0000178;  35 docs/s;  10505 sec
[2021-06-06 02:58:49,527 INFO] Step 28550/50000; xent: 2.12; lr: 0.0000178;  35 docs/s;  10523 sec
[2021-06-06 02:59:08,477 INFO] Step 28600/50000; xent: 2.05; lr: 0.0000177;  36 docs/s;  10542 sec
[2021-06-06 02:59:26,689 INFO] Step 28650/50000; xent: 2.32; lr: 0.0000177;  36 docs/s;  10560 sec
[2021-06-06 02:59:44,955 INFO] Step 28700/50000; xent: 2.10; lr: 0.0000177;  37 docs/s;  10578 sec
[2021-06-06 03:00:03,347 INFO] Step 28750/50000; xent: 2.21; lr: 0.0000177;  36 docs/s;  10597 sec
[2021-06-06 03:00:21,794 INFO] Step 28800/50000; xent: 2.24; lr: 0.0000177;  32 docs/s;  10615 sec
[2021-06-06 03:00:40,264 INFO] Step 28850/50000; xent: 2.34; lr: 0.0000177;  33 docs/s;  10634 sec
[2021-06-06 03:00:58,691 INFO] Step 28900/50000; xent: 2.18; lr: 0.0000176;  35 docs/s;  10652 sec
[2021-06-06 03:01:17,177 INFO] Step 28950/50000; xent: 2.24; lr: 0.0000176;  33 docs/s;  10671 sec
[2021-06-06 03:01:35,682 INFO] Step 29000/50000; xent: 2.12; lr: 0.0000176;  39 docs/s;  10689 sec
[2021-06-06 03:01:54,080 INFO] Step 29050/50000; xent: 2.27; lr: 0.0000176;  33 docs/s;  10708 sec
[2021-06-06 03:02:12,621 INFO] Step 29100/50000; xent: 2.23; lr: 0.0000176;  33 docs/s;  10726 sec
[2021-06-06 03:02:30,825 INFO] Step 29150/50000; xent: 2.13; lr: 0.0000176;  36 docs/s;  10744 sec
[2021-06-06 03:02:49,092 INFO] Step 29200/50000; xent: 1.99; lr: 0.0000176;  40 docs/s;  10763 sec
[2021-06-06 03:03:07,626 INFO] Step 29250/50000; xent: 2.23; lr: 0.0000175;  33 docs/s;  10781 sec
[2021-06-06 03:03:25,973 INFO] Step 29300/50000; xent: 2.24; lr: 0.0000175;  36 docs/s;  10799 sec
[2021-06-06 03:03:44,038 INFO] Step 29350/50000; xent: 2.01; lr: 0.0000175;  41 docs/s;  10818 sec
[2021-06-06 03:04:02,317 INFO] Step 29400/50000; xent: 2.17; lr: 0.0000175;  38 docs/s;  10836 sec
[2021-06-06 03:04:20,449 INFO] Step 29450/50000; xent: 2.10; lr: 0.0000175;  32 docs/s;  10854 sec
[2021-06-06 03:04:38,765 INFO] Step 29500/50000; xent: 2.14; lr: 0.0000175;  37 docs/s;  10872 sec
[2021-06-06 03:04:57,217 INFO] Step 29550/50000; xent: 2.24; lr: 0.0000175;  35 docs/s;  10891 sec
[2021-06-06 03:05:15,395 INFO] Step 29600/50000; xent: 2.20; lr: 0.0000174;  36 docs/s;  10909 sec
[2021-06-06 03:05:33,649 INFO] Step 29650/50000; xent: 2.15; lr: 0.0000174;  36 docs/s;  10927 sec
[2021-06-06 03:05:51,973 INFO] Step 29700/50000; xent: 2.11; lr: 0.0000174;  37 docs/s;  10945 sec
[2021-06-06 03:06:10,010 INFO] Step 29750/50000; xent: 2.44; lr: 0.0000174;  30 docs/s;  10963 sec
[2021-06-06 03:06:28,477 INFO] Step 29800/50000; xent: 2.18; lr: 0.0000174;  37 docs/s;  10982 sec
[2021-06-06 03:06:46,745 INFO] Step 29850/50000; xent: 2.14; lr: 0.0000174;  35 docs/s;  11000 sec
[2021-06-06 03:07:05,231 INFO] Step 29900/50000; xent: 1.97; lr: 0.0000173;  38 docs/s;  11019 sec
[2021-06-06 03:07:23,372 INFO] Step 29950/50000; xent: 2.38; lr: 0.0000173;  32 docs/s;  11037 sec
[2021-06-06 03:07:41,436 INFO] Step 30000/50000; xent: 2.41; lr: 0.0000173;  32 docs/s;  11055 sec
[2021-06-06 03:07:41,438 INFO] Saving checkpoint ../models/bert_ext\model_step_30000.pt
[2021-06-06 03:08:06,074 INFO] Step 30050/50000; xent: 2.25; lr: 0.0000173;  26 docs/s;  11080 sec
[2021-06-06 03:08:24,196 INFO] Step 30100/50000; xent: 2.11; lr: 0.0000173;  38 docs/s;  11098 sec
[2021-06-06 03:08:42,683 INFO] Step 30150/50000; xent: 2.09; lr: 0.0000173;  34 docs/s;  11116 sec
[2021-06-06 03:09:01,152 INFO] Step 30200/50000; xent: 2.20; lr: 0.0000173;  33 docs/s;  11135 sec
[2021-06-06 03:09:19,414 INFO] Step 30250/50000; xent: 2.13; lr: 0.0000172;  39 docs/s;  11153 sec
[2021-06-06 03:09:37,384 INFO] Step 30300/50000; xent: 2.09; lr: 0.0000172;  36 docs/s;  11171 sec
[2021-06-06 03:09:55,980 INFO] Step 30350/50000; xent: 2.16; lr: 0.0000172;  34 docs/s;  11189 sec
[2021-06-06 03:10:14,433 INFO] Step 30400/50000; xent: 2.00; lr: 0.0000172;  38 docs/s;  11208 sec
[2021-06-06 03:10:32,567 INFO] Step 30450/50000; xent: 2.16; lr: 0.0000172;  33 docs/s;  11226 sec
[2021-06-06 03:10:35,525 INFO] Loading train dataset from ../bert_data/train.3.bert.pt, number of examples: 15918
[2021-06-06 03:10:52,717 INFO] Step 30500/50000; xent: 2.22; lr: 0.0000172;  31 docs/s;  11246 sec
[2021-06-06 03:11:11,184 INFO] Step 30550/50000; xent: 2.15; lr: 0.0000172;  33 docs/s;  11265 sec
[2021-06-06 03:11:29,197 INFO] Step 30600/50000; xent: 2.21; lr: 0.0000171;  34 docs/s;  11283 sec
[2021-06-06 03:11:47,465 INFO] Step 30650/50000; xent: 2.15; lr: 0.0000171;  34 docs/s;  11301 sec
[2021-06-06 03:12:05,899 INFO] Step 30700/50000; xent: 2.40; lr: 0.0000171;  29 docs/s;  11319 sec
[2021-06-06 03:12:24,396 INFO] Step 30750/50000; xent: 2.13; lr: 0.0000171;  33 docs/s;  11338 sec
[2021-06-06 03:12:42,498 INFO] Step 30800/50000; xent: 2.39; lr: 0.0000171;  30 docs/s;  11356 sec
[2021-06-06 03:13:00,702 INFO] Step 30850/50000; xent: 2.14; lr: 0.0000171;  32 docs/s;  11374 sec
[2021-06-06 03:13:19,054 INFO] Step 30900/50000; xent: 2.19; lr: 0.0000171;  33 docs/s;  11393 sec
[2021-06-06 03:13:37,460 INFO] Step 30950/50000; xent: 2.29; lr: 0.0000171;  31 docs/s;  11411 sec
[2021-06-06 03:13:55,916 INFO] Step 31000/50000; xent: 2.20; lr: 0.0000170;  32 docs/s;  11429 sec
[2021-06-06 03:14:13,940 INFO] Step 31050/50000; xent: 2.04; lr: 0.0000170;  37 docs/s;  11447 sec
[2021-06-06 03:14:32,582 INFO] Step 31100/50000; xent: 2.04; lr: 0.0000170;  34 docs/s;  11466 sec
[2021-06-06 03:14:50,910 INFO] Step 31150/50000; xent: 2.25; lr: 0.0000170;  32 docs/s;  11484 sec
[2021-06-06 03:15:09,439 INFO] Step 31200/50000; xent: 2.09; lr: 0.0000170;  32 docs/s;  11503 sec
[2021-06-06 03:15:27,791 INFO] Step 31250/50000; xent: 2.24; lr: 0.0000170;  33 docs/s;  11521 sec
[2021-06-06 03:15:46,060 INFO] Step 31300/50000; xent: 2.56; lr: 0.0000170;  28 docs/s;  11540 sec
[2021-06-06 03:16:04,655 INFO] Step 31350/50000; xent: 2.25; lr: 0.0000169;  33 docs/s;  11558 sec
[2021-06-06 03:16:22,721 INFO] Step 31400/50000; xent: 2.11; lr: 0.0000169;  36 docs/s;  11576 sec
[2021-06-06 03:16:41,203 INFO] Step 31450/50000; xent: 2.31; lr: 0.0000169;  32 docs/s;  11595 sec
[2021-06-06 03:16:59,553 INFO] Step 31500/50000; xent: 2.27; lr: 0.0000169;  29 docs/s;  11613 sec
[2021-06-06 03:17:17,975 INFO] Step 31550/50000; xent: 2.04; lr: 0.0000169;  38 docs/s;  11631 sec
[2021-06-06 03:17:35,941 INFO] Step 31600/50000; xent: 2.36; lr: 0.0000169;  29 docs/s;  11649 sec
[2021-06-06 03:17:54,086 INFO] Step 31650/50000; xent: 2.31; lr: 0.0000169;  33 docs/s;  11668 sec
[2021-06-06 03:18:12,230 INFO] Step 31700/50000; xent: 2.09; lr: 0.0000168;  34 docs/s;  11686 sec
[2021-06-06 03:18:30,329 INFO] Step 31750/50000; xent: 2.29; lr: 0.0000168;  30 docs/s;  11704 sec
[2021-06-06 03:18:49,112 INFO] Step 31800/50000; xent: 2.24; lr: 0.0000168;  34 docs/s;  11723 sec
[2021-06-06 03:19:07,700 INFO] Step 31850/50000; xent: 2.21; lr: 0.0000168;  30 docs/s;  11741 sec
[2021-06-06 03:19:26,512 INFO] Step 31900/50000; xent: 2.22; lr: 0.0000168;  35 docs/s;  11760 sec
[2021-06-06 03:19:45,086 INFO] Step 31950/50000; xent: 2.21; lr: 0.0000168;  34 docs/s;  11779 sec
[2021-06-06 03:20:03,600 INFO] Step 32000/50000; xent: 2.12; lr: 0.0000168;  34 docs/s;  11797 sec
[2021-06-06 03:20:22,437 INFO] Step 32050/50000; xent: 2.26; lr: 0.0000168;  32 docs/s;  11816 sec
[2021-06-06 03:20:40,899 INFO] Step 32100/50000; xent: 2.09; lr: 0.0000167;  32 docs/s;  11834 sec
[2021-06-06 03:20:59,200 INFO] Step 32150/50000; xent: 1.97; lr: 0.0000167;  36 docs/s;  11853 sec
[2021-06-06 03:21:17,529 INFO] Step 32200/50000; xent: 2.15; lr: 0.0000167;  33 docs/s;  11871 sec
[2021-06-06 03:21:35,781 INFO] Step 32250/50000; xent: 2.26; lr: 0.0000167;  31 docs/s;  11889 sec
[2021-06-06 03:21:53,795 INFO] Step 32300/50000; xent: 2.24; lr: 0.0000167;  31 docs/s;  11907 sec
[2021-06-06 03:22:12,341 INFO] Step 32350/50000; xent: 2.17; lr: 0.0000167;  34 docs/s;  11926 sec
[2021-06-06 03:22:30,872 INFO] Step 32400/50000; xent: 2.23; lr: 0.0000167;  32 docs/s;  11944 sec
[2021-06-06 03:22:49,221 INFO] Step 32450/50000; xent: 2.11; lr: 0.0000167;  33 docs/s;  11963 sec
[2021-06-06 03:23:07,620 INFO] Step 32500/50000; xent: 2.40; lr: 0.0000166;  28 docs/s;  11981 sec
[2021-06-06 03:23:25,886 INFO] Step 32550/50000; xent: 2.29; lr: 0.0000166;  30 docs/s;  11999 sec
[2021-06-06 03:23:44,222 INFO] Step 32600/50000; xent: 2.15; lr: 0.0000166;  35 docs/s;  12018 sec
[2021-06-06 03:24:02,575 INFO] Step 32650/50000; xent: 2.13; lr: 0.0000166;  34 docs/s;  12036 sec
[2021-06-06 03:24:20,852 INFO] Step 32700/50000; xent: 2.30; lr: 0.0000166;  30 docs/s;  12054 sec
[2021-06-06 03:24:39,038 INFO] Step 32750/50000; xent: 2.17; lr: 0.0000166;  33 docs/s;  12073 sec
[2021-06-06 03:24:57,375 INFO] Step 32800/50000; xent: 2.27; lr: 0.0000166;  32 docs/s;  12091 sec
[2021-06-06 03:25:15,593 INFO] Step 32850/50000; xent: 2.19; lr: 0.0000166;  33 docs/s;  12109 sec
[2021-06-06 03:25:33,661 INFO] Step 32900/50000; xent: 2.39; lr: 0.0000165;  30 docs/s;  12127 sec
[2021-06-06 03:25:52,410 INFO] Step 32950/50000; xent: 2.08; lr: 0.0000165;  34 docs/s;  12146 sec
[2021-06-06 03:26:10,769 INFO] Step 33000/50000; xent: 2.21; lr: 0.0000165;  32 docs/s;  12164 sec
[2021-06-06 03:26:29,289 INFO] Step 33050/50000; xent: 2.03; lr: 0.0000165;  35 docs/s;  12183 sec
[2021-06-06 03:26:47,603 INFO] Step 33100/50000; xent: 2.32; lr: 0.0000165;  30 docs/s;  12201 sec
[2021-06-06 03:26:59,952 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-06 03:27:07,725 INFO] Step 33150/50000; xent: 2.24; lr: 0.0000165;  30 docs/s;  12221 sec
[2021-06-06 03:27:25,916 INFO] Step 33200/50000; xent: 2.36; lr: 0.0000165;  35 docs/s;  12239 sec
[2021-06-06 03:27:44,393 INFO] Step 33250/50000; xent: 2.21; lr: 0.0000165;  40 docs/s;  12258 sec
[2021-06-06 03:28:02,956 INFO] Step 33300/50000; xent: 2.19; lr: 0.0000164;  34 docs/s;  12276 sec
[2021-06-06 03:28:21,259 INFO] Step 33350/50000; xent: 2.21; lr: 0.0000164;  37 docs/s;  12295 sec
[2021-06-06 03:28:39,401 INFO] Step 33400/50000; xent: 2.41; lr: 0.0000164;  29 docs/s;  12313 sec
[2021-06-06 03:28:57,385 INFO] Step 33450/50000; xent: 2.26; lr: 0.0000164;  34 docs/s;  12331 sec
[2021-06-06 03:29:15,288 INFO] Step 33500/50000; xent: 2.33; lr: 0.0000164;  33 docs/s;  12349 sec
[2021-06-06 03:29:33,421 INFO] Step 33550/50000; xent: 2.37; lr: 0.0000164;  34 docs/s;  12367 sec
[2021-06-06 03:29:52,213 INFO] Step 33600/50000; xent: 2.18; lr: 0.0000164;  36 docs/s;  12386 sec
[2021-06-06 03:30:10,313 INFO] Step 33650/50000; xent: 2.29; lr: 0.0000164;  36 docs/s;  12404 sec
[2021-06-06 03:30:28,409 INFO] Step 33700/50000; xent: 2.38; lr: 0.0000163;  35 docs/s;  12422 sec
[2021-06-06 03:30:46,719 INFO] Step 33750/50000; xent: 2.26; lr: 0.0000163;  34 docs/s;  12440 sec
[2021-06-06 03:31:04,996 INFO] Step 33800/50000; xent: 2.28; lr: 0.0000163;  36 docs/s;  12458 sec
[2021-06-06 03:31:23,410 INFO] Step 33850/50000; xent: 2.41; lr: 0.0000163;  34 docs/s;  12477 sec
[2021-06-06 03:31:41,963 INFO] Step 33900/50000; xent: 2.35; lr: 0.0000163;  33 docs/s;  12495 sec
[2021-06-06 03:32:00,338 INFO] Step 33950/50000; xent: 2.39; lr: 0.0000163;  32 docs/s;  12514 sec
[2021-06-06 03:32:18,358 INFO] Step 34000/50000; xent: 2.19; lr: 0.0000163;  36 docs/s;  12532 sec
[2021-06-06 03:32:36,632 INFO] Step 34050/50000; xent: 2.44; lr: 0.0000163;  32 docs/s;  12550 sec
[2021-06-06 03:32:54,514 INFO] Step 34100/50000; xent: 2.07; lr: 0.0000162;  39 docs/s;  12568 sec
[2021-06-06 03:33:12,184 INFO] Step 34150/50000; xent: 2.44; lr: 0.0000162;  34 docs/s;  12586 sec
[2021-06-06 03:33:30,361 INFO] Step 34200/50000; xent: 2.30; lr: 0.0000162;  35 docs/s;  12604 sec
[2021-06-06 03:33:49,027 INFO] Step 34250/50000; xent: 2.42; lr: 0.0000162;  33 docs/s;  12623 sec
[2021-06-06 03:34:06,663 INFO] Step 34300/50000; xent: 2.17; lr: 0.0000162;  35 docs/s;  12640 sec
[2021-06-06 03:34:24,746 INFO] Step 34350/50000; xent: 2.28; lr: 0.0000162;  32 docs/s;  12658 sec
[2021-06-06 03:34:42,863 INFO] Step 34400/50000; xent: 2.18; lr: 0.0000162;  37 docs/s;  12676 sec
[2021-06-06 03:35:01,001 INFO] Step 34450/50000; xent: 2.50; lr: 0.0000162;  33 docs/s;  12694 sec
[2021-06-06 03:35:19,209 INFO] Step 34500/50000; xent: 2.22; lr: 0.0000162;  38 docs/s;  12713 sec
[2021-06-06 03:35:37,494 INFO] Step 34550/50000; xent: 2.28; lr: 0.0000161;  34 docs/s;  12731 sec
[2021-06-06 03:35:55,628 INFO] Step 34600/50000; xent: 2.33; lr: 0.0000161;  33 docs/s;  12749 sec
[2021-06-06 03:36:14,038 INFO] Step 34650/50000; xent: 2.50; lr: 0.0000161;  32 docs/s;  12768 sec
[2021-06-06 03:36:32,281 INFO] Step 34700/50000; xent: 2.26; lr: 0.0000161;  33 docs/s;  12786 sec
[2021-06-06 03:36:50,483 INFO] Step 34750/50000; xent: 2.24; lr: 0.0000161;  34 docs/s;  12804 sec
[2021-06-06 03:37:08,801 INFO] Step 34800/50000; xent: 2.40; lr: 0.0000161;  35 docs/s;  12822 sec
[2021-06-06 03:37:27,036 INFO] Step 34850/50000; xent: 2.35; lr: 0.0000161;  30 docs/s;  12841 sec
[2021-06-06 03:37:45,454 INFO] Step 34900/50000; xent: 2.28; lr: 0.0000161;  34 docs/s;  12859 sec
[2021-06-06 03:38:03,760 INFO] Step 34950/50000; xent: 2.23; lr: 0.0000160;  35 docs/s;  12877 sec
[2021-06-06 03:38:22,447 INFO] Step 35000/50000; xent: 2.27; lr: 0.0000160;  35 docs/s;  12896 sec
[2021-06-06 03:38:22,448 INFO] Saving checkpoint ../models/bert_ext\model_step_35000.pt
[2021-06-06 03:38:46,210 INFO] Step 35050/50000; xent: 2.40; lr: 0.0000160;  25 docs/s;  12920 sec
[2021-06-06 03:39:04,531 INFO] Step 35100/50000; xent: 2.24; lr: 0.0000160;  35 docs/s;  12938 sec
[2021-06-06 03:39:22,899 INFO] Step 35150/50000; xent: 2.37; lr: 0.0000160;  32 docs/s;  12956 sec
[2021-06-06 03:39:40,957 INFO] Step 35200/50000; xent: 2.29; lr: 0.0000160;  35 docs/s;  12974 sec
[2021-06-06 03:39:59,171 INFO] Step 35250/50000; xent: 2.38; lr: 0.0000160;  35 docs/s;  12993 sec
[2021-06-06 03:40:17,152 INFO] Step 35300/50000; xent: 2.31; lr: 0.0000160;  32 docs/s;  13011 sec
[2021-06-06 03:40:35,890 INFO] Step 35350/50000; xent: 2.15; lr: 0.0000160;  35 docs/s;  13029 sec
[2021-06-06 03:40:53,660 INFO] Step 35400/50000; xent: 2.13; lr: 0.0000159;  38 docs/s;  13047 sec
[2021-06-06 03:41:11,928 INFO] Step 35450/50000; xent: 2.42; lr: 0.0000159;  31 docs/s;  13065 sec
[2021-06-06 03:41:30,517 INFO] Step 35500/50000; xent: 2.37; lr: 0.0000159;  32 docs/s;  13084 sec
[2021-06-06 03:41:48,646 INFO] Step 35550/50000; xent: 2.36; lr: 0.0000159;  36 docs/s;  13102 sec
[2021-06-06 03:42:07,346 INFO] Step 35600/50000; xent: 2.25; lr: 0.0000159;  33 docs/s;  13121 sec
[2021-06-06 03:42:25,505 INFO] Step 35650/50000; xent: 2.26; lr: 0.0000159;  36 docs/s;  13139 sec
[2021-06-06 03:42:31,790 INFO] Loading train dataset from ../bert_data/train.1.bert.pt, number of examples: 15951
[2021-06-06 03:42:46,196 INFO] Step 35700/50000; xent: 2.38; lr: 0.0000159;  28 docs/s;  13160 sec
[2021-06-06 03:43:04,396 INFO] Step 35750/50000; xent: 2.04; lr: 0.0000159;  37 docs/s;  13178 sec
[2021-06-06 03:43:22,685 INFO] Step 35800/50000; xent: 2.42; lr: 0.0000159;  35 docs/s;  13196 sec
[2021-06-06 03:43:41,081 INFO] Step 35850/50000; xent: 2.17; lr: 0.0000158;  36 docs/s;  13215 sec
[2021-06-06 03:43:59,869 INFO] Step 35900/50000; xent: 2.15; lr: 0.0000158;  36 docs/s;  13233 sec
[2021-06-06 03:44:18,435 INFO] Step 35950/50000; xent: 2.16; lr: 0.0000158;  34 docs/s;  13252 sec
[2021-06-06 03:44:36,612 INFO] Step 36000/50000; xent: 2.22; lr: 0.0000158;  35 docs/s;  13270 sec
[2021-06-06 03:44:54,713 INFO] Step 36050/50000; xent: 2.22; lr: 0.0000158;  33 docs/s;  13288 sec
[2021-06-06 03:45:13,009 INFO] Step 36100/50000; xent: 2.42; lr: 0.0000158;  29 docs/s;  13306 sec
[2021-06-06 03:45:31,458 INFO] Step 36150/50000; xent: 2.02; lr: 0.0000158;  37 docs/s;  13325 sec
[2021-06-06 03:45:49,804 INFO] Step 36200/50000; xent: 2.25; lr: 0.0000158;  36 docs/s;  13343 sec
[2021-06-06 03:46:08,320 INFO] Step 36250/50000; xent: 2.18; lr: 0.0000158;  36 docs/s;  13362 sec
[2021-06-06 03:46:26,434 INFO] Step 36300/50000; xent: 2.16; lr: 0.0000157;  35 docs/s;  13380 sec
[2021-06-06 03:46:44,510 INFO] Step 36350/50000; xent: 2.24; lr: 0.0000157;  35 docs/s;  13398 sec
[2021-06-06 03:47:03,140 INFO] Step 36400/50000; xent: 2.14; lr: 0.0000157;  35 docs/s;  13417 sec
[2021-06-06 03:47:21,540 INFO] Step 36450/50000; xent: 2.30; lr: 0.0000157;  30 docs/s;  13435 sec
[2021-06-06 03:47:39,459 INFO] Step 36500/50000; xent: 2.05; lr: 0.0000157;  40 docs/s;  13453 sec
[2021-06-06 03:47:57,611 INFO] Step 36550/50000; xent: 2.17; lr: 0.0000157;  35 docs/s;  13471 sec
[2021-06-06 03:48:15,763 INFO] Step 36600/50000; xent: 2.09; lr: 0.0000157;  33 docs/s;  13489 sec
[2021-06-06 03:48:34,558 INFO] Step 36650/50000; xent: 2.18; lr: 0.0000157;  34 docs/s;  13508 sec
[2021-06-06 03:48:52,793 INFO] Step 36700/50000; xent: 2.33; lr: 0.0000157;  33 docs/s;  13526 sec
[2021-06-06 03:49:11,045 INFO] Step 36750/50000; xent: 2.06; lr: 0.0000156;  37 docs/s;  13545 sec
[2021-06-06 03:49:29,502 INFO] Step 36800/50000; xent: 2.36; lr: 0.0000156;  31 docs/s;  13563 sec
[2021-06-06 03:49:47,986 INFO] Step 36850/50000; xent: 2.29; lr: 0.0000156;  33 docs/s;  13581 sec
[2021-06-06 03:50:06,599 INFO] Step 36900/50000; xent: 2.08; lr: 0.0000156;  36 docs/s;  13600 sec
[2021-06-06 03:50:24,820 INFO] Step 36950/50000; xent: 2.06; lr: 0.0000156;  37 docs/s;  13618 sec
[2021-06-06 03:50:43,148 INFO] Step 37000/50000; xent: 2.30; lr: 0.0000156;  34 docs/s;  13637 sec
[2021-06-06 03:51:01,579 INFO] Step 37050/50000; xent: 2.11; lr: 0.0000156;  35 docs/s;  13655 sec
[2021-06-06 03:51:19,741 INFO] Step 37100/50000; xent: 2.21; lr: 0.0000156;  33 docs/s;  13673 sec
[2021-06-06 03:51:37,969 INFO] Step 37150/50000; xent: 2.16; lr: 0.0000156;  36 docs/s;  13691 sec
[2021-06-06 03:51:56,353 INFO] Step 37200/50000; xent: 2.25; lr: 0.0000156;  33 docs/s;  13710 sec
[2021-06-06 03:52:14,637 INFO] Step 37250/50000; xent: 2.19; lr: 0.0000155;  36 docs/s;  13728 sec
[2021-06-06 03:52:32,994 INFO] Step 37300/50000; xent: 2.28; lr: 0.0000155;  33 docs/s;  13746 sec
[2021-06-06 03:52:51,409 INFO] Step 37350/50000; xent: 2.24; lr: 0.0000155;  31 docs/s;  13765 sec
[2021-06-06 03:53:09,975 INFO] Step 37400/50000; xent: 2.20; lr: 0.0000155;  36 docs/s;  13783 sec
[2021-06-06 03:53:28,245 INFO] Step 37450/50000; xent: 2.05; lr: 0.0000155;  40 docs/s;  13802 sec
[2021-06-06 03:53:46,642 INFO] Step 37500/50000; xent: 2.17; lr: 0.0000155;  38 docs/s;  13820 sec
[2021-06-06 03:54:04,888 INFO] Step 37550/50000; xent: 2.30; lr: 0.0000155;  33 docs/s;  13838 sec
[2021-06-06 03:54:23,044 INFO] Step 37600/50000; xent: 2.11; lr: 0.0000155;  33 docs/s;  13857 sec
[2021-06-06 03:54:41,013 INFO] Step 37650/50000; xent: 2.37; lr: 0.0000155;  32 docs/s;  13874 sec
[2021-06-06 03:54:59,270 INFO] Step 37700/50000; xent: 2.33; lr: 0.0000155;  35 docs/s;  13893 sec
[2021-06-06 03:55:17,419 INFO] Step 37750/50000; xent: 2.01; lr: 0.0000154;  38 docs/s;  13911 sec
[2021-06-06 03:55:35,943 INFO] Step 37800/50000; xent: 2.02; lr: 0.0000154;  37 docs/s;  13929 sec
[2021-06-06 03:55:54,048 INFO] Step 37850/50000; xent: 2.46; lr: 0.0000154;  28 docs/s;  13948 sec
[2021-06-06 03:56:12,237 INFO] Step 37900/50000; xent: 2.12; lr: 0.0000154;  35 docs/s;  13966 sec
[2021-06-06 03:56:30,582 INFO] Step 37950/50000; xent: 2.21; lr: 0.0000154;  37 docs/s;  13984 sec
[2021-06-06 03:56:48,568 INFO] Step 38000/50000; xent: 2.19; lr: 0.0000154;  33 docs/s;  14002 sec
[2021-06-06 03:57:07,037 INFO] Step 38050/50000; xent: 2.16; lr: 0.0000154;  38 docs/s;  14021 sec
[2021-06-06 03:57:25,036 INFO] Step 38100/50000; xent: 2.27; lr: 0.0000154;  34 docs/s;  14039 sec
[2021-06-06 03:57:43,263 INFO] Step 38150/50000; xent: 2.16; lr: 0.0000154;  34 docs/s;  14057 sec
[2021-06-06 03:57:54,916 INFO] Loading train dataset from ../bert_data/train.1.bert.pt, number of examples: 15951
[2021-06-06 03:58:03,270 INFO] Step 38200/50000; xent: 2.34; lr: 0.0000153;  28 docs/s;  14077 sec
[2021-06-06 03:58:21,818 INFO] Step 38250/50000; xent: 2.06; lr: 0.0000153;  34 docs/s;  14095 sec
[2021-06-06 03:58:40,131 INFO] Step 38300/50000; xent: 1.86; lr: 0.0000153;  36 docs/s;  14114 sec
[2021-06-06 03:58:58,331 INFO] Step 38350/50000; xent: 1.78; lr: 0.0000153;  37 docs/s;  14132 sec
[2021-06-06 03:59:16,376 INFO] Step 38400/50000; xent: 2.02; lr: 0.0000153;  35 docs/s;  14150 sec
[2021-06-06 03:59:34,816 INFO] Step 38450/50000; xent: 1.86; lr: 0.0000153;  37 docs/s;  14168 sec
[2021-06-06 03:59:52,955 INFO] Step 38500/50000; xent: 2.20; lr: 0.0000153;  31 docs/s;  14186 sec
[2021-06-06 04:00:10,812 INFO] Step 38550/50000; xent: 1.94; lr: 0.0000153;  37 docs/s;  14204 sec
[2021-06-06 04:00:29,102 INFO] Step 38600/50000; xent: 2.09; lr: 0.0000153;  34 docs/s;  14223 sec
[2021-06-06 04:00:47,348 INFO] Step 38650/50000; xent: 2.14; lr: 0.0000153;  33 docs/s;  14241 sec
[2021-06-06 04:01:05,763 INFO] Step 38700/50000; xent: 2.13; lr: 0.0000152;  32 docs/s;  14259 sec
[2021-06-06 04:01:23,818 INFO] Step 38750/50000; xent: 2.06; lr: 0.0000152;  33 docs/s;  14277 sec
[2021-06-06 04:01:42,220 INFO] Step 38800/50000; xent: 1.88; lr: 0.0000152;  40 docs/s;  14296 sec
[2021-06-06 04:02:00,436 INFO] Step 38850/50000; xent: 2.08; lr: 0.0000152;  33 docs/s;  14314 sec
[2021-06-06 04:02:19,087 INFO] Step 38900/50000; xent: 1.85; lr: 0.0000152;  39 docs/s;  14333 sec
[2021-06-06 04:02:37,301 INFO] Step 38950/50000; xent: 1.89; lr: 0.0000152;  34 docs/s;  14351 sec
[2021-06-06 04:02:55,948 INFO] Step 39000/50000; xent: 2.01; lr: 0.0000152;  34 docs/s;  14369 sec
[2021-06-06 04:03:14,362 INFO] Step 39050/50000; xent: 1.95; lr: 0.0000152;  36 docs/s;  14388 sec
[2021-06-06 04:03:33,152 INFO] Step 39100/50000; xent: 2.11; lr: 0.0000152;  34 docs/s;  14407 sec
[2021-06-06 04:03:51,352 INFO] Step 39150/50000; xent: 2.08; lr: 0.0000152;  31 docs/s;  14425 sec
[2021-06-06 04:04:09,515 INFO] Step 39200/50000; xent: 1.86; lr: 0.0000152;  38 docs/s;  14443 sec
[2021-06-06 04:04:27,743 INFO] Step 39250/50000; xent: 2.17; lr: 0.0000151;  34 docs/s;  14461 sec
[2021-06-06 04:04:45,874 INFO] Step 39300/50000; xent: 1.92; lr: 0.0000151;  35 docs/s;  14479 sec
[2021-06-06 04:05:03,947 INFO] Step 39350/50000; xent: 1.99; lr: 0.0000151;  37 docs/s;  14497 sec
[2021-06-06 04:05:21,931 INFO] Step 39400/50000; xent: 2.06; lr: 0.0000151;  35 docs/s;  14515 sec
[2021-06-06 04:05:40,493 INFO] Step 39450/50000; xent: 2.00; lr: 0.0000151;  33 docs/s;  14534 sec
[2021-06-06 04:05:58,537 INFO] Step 39500/50000; xent: 2.17; lr: 0.0000151;  34 docs/s;  14552 sec
[2021-06-06 04:06:17,315 INFO] Step 39550/50000; xent: 1.87; lr: 0.0000151;  35 docs/s;  14571 sec
[2021-06-06 04:06:35,499 INFO] Step 39600/50000; xent: 1.98; lr: 0.0000151;  36 docs/s;  14589 sec
[2021-06-06 04:06:53,684 INFO] Step 39650/50000; xent: 2.11; lr: 0.0000151;  34 docs/s;  14607 sec
[2021-06-06 04:07:12,274 INFO] Step 39700/50000; xent: 1.91; lr: 0.0000151;  36 docs/s;  14626 sec
[2021-06-06 04:07:31,032 INFO] Step 39750/50000; xent: 1.91; lr: 0.0000150;  35 docs/s;  14645 sec
[2021-06-06 04:07:49,095 INFO] Step 39800/50000; xent: 2.05; lr: 0.0000150;  34 docs/s;  14663 sec
[2021-06-06 04:08:07,415 INFO] Step 39850/50000; xent: 2.06; lr: 0.0000150;  35 docs/s;  14681 sec
[2021-06-06 04:08:25,830 INFO] Step 39900/50000; xent: 1.96; lr: 0.0000150;  32 docs/s;  14699 sec
[2021-06-06 04:08:43,748 INFO] Step 39950/50000; xent: 1.88; lr: 0.0000150;  38 docs/s;  14717 sec
[2021-06-06 04:09:02,242 INFO] Step 40000/50000; xent: 2.07; lr: 0.0000150;  35 docs/s;  14736 sec
[2021-06-06 04:09:02,244 INFO] Saving checkpoint ../models/bert_ext\model_step_40000.pt
[2021-06-06 04:09:26,944 INFO] Step 40050/50000; xent: 2.04; lr: 0.0000150;  25 docs/s;  14760 sec
[2021-06-06 04:09:44,900 INFO] Step 40100/50000; xent: 1.93; lr: 0.0000150;  37 docs/s;  14778 sec
[2021-06-06 04:10:02,980 INFO] Step 40150/50000; xent: 2.14; lr: 0.0000150;  28 docs/s;  14796 sec
[2021-06-06 04:10:21,283 INFO] Step 40200/50000; xent: 1.87; lr: 0.0000150;  38 docs/s;  14815 sec
[2021-06-06 04:10:39,388 INFO] Step 40250/50000; xent: 2.01; lr: 0.0000150;  33 docs/s;  14833 sec
[2021-06-06 04:10:58,050 INFO] Step 40300/50000; xent: 2.06; lr: 0.0000149;  32 docs/s;  14852 sec
[2021-06-06 04:11:15,939 INFO] Step 40350/50000; xent: 2.06; lr: 0.0000149;  32 docs/s;  14869 sec
[2021-06-06 04:11:34,405 INFO] Step 40400/50000; xent: 2.07; lr: 0.0000149;  35 docs/s;  14888 sec
[2021-06-06 04:11:52,547 INFO] Step 40450/50000; xent: 1.96; lr: 0.0000149;  34 docs/s;  14906 sec
[2021-06-06 04:12:10,903 INFO] Step 40500/50000; xent: 2.02; lr: 0.0000149;  33 docs/s;  14924 sec
[2021-06-06 04:12:29,251 INFO] Step 40550/50000; xent: 1.95; lr: 0.0000149;  36 docs/s;  14943 sec
[2021-06-06 04:12:47,401 INFO] Step 40600/50000; xent: 2.07; lr: 0.0000149;  34 docs/s;  14961 sec
[2021-06-06 04:13:05,536 INFO] Step 40650/50000; xent: 2.05; lr: 0.0000149;  35 docs/s;  14979 sec
[2021-06-06 04:13:24,322 INFO] Loading train dataset from ../bert_data/train.2.bert.pt, number of examples: 15944
[2021-06-06 04:13:25,470 INFO] Step 40700/50000; xent: 1.94; lr: 0.0000149;  33 docs/s;  14999 sec
[2021-06-06 04:13:43,447 INFO] Step 40750/50000; xent: 1.93; lr: 0.0000149;  39 docs/s;  15017 sec
[2021-06-06 04:14:01,805 INFO] Step 40800/50000; xent: 1.92; lr: 0.0000149;  38 docs/s;  15035 sec
[2021-06-06 04:14:20,262 INFO] Step 40850/50000; xent: 2.10; lr: 0.0000148;  34 docs/s;  15054 sec
[2021-06-06 04:14:38,819 INFO] Step 40900/50000; xent: 2.15; lr: 0.0000148;  36 docs/s;  15072 sec
[2021-06-06 04:14:57,182 INFO] Step 40950/50000; xent: 2.09; lr: 0.0000148;  33 docs/s;  15091 sec
[2021-06-06 04:15:15,360 INFO] Step 41000/50000; xent: 1.93; lr: 0.0000148;  38 docs/s;  15109 sec
[2021-06-06 04:15:34,048 INFO] Step 41050/50000; xent: 2.23; lr: 0.0000148;  31 docs/s;  15128 sec
[2021-06-06 04:15:52,439 INFO] Step 41100/50000; xent: 2.08; lr: 0.0000148;  32 docs/s;  15146 sec
[2021-06-06 04:16:10,738 INFO] Step 41150/50000; xent: 1.88; lr: 0.0000148;  39 docs/s;  15164 sec
[2021-06-06 04:16:28,985 INFO] Step 41200/50000; xent: 2.06; lr: 0.0000148;  35 docs/s;  15182 sec
[2021-06-06 04:16:47,407 INFO] Step 41250/50000; xent: 2.07; lr: 0.0000148;  33 docs/s;  15201 sec
[2021-06-06 04:17:05,451 INFO] Step 41300/50000; xent: 2.08; lr: 0.0000148;  37 docs/s;  15219 sec
[2021-06-06 04:17:24,049 INFO] Step 41350/50000; xent: 2.06; lr: 0.0000148;  39 docs/s;  15238 sec
[2021-06-06 04:17:42,584 INFO] Step 41400/50000; xent: 1.87; lr: 0.0000147;  38 docs/s;  15256 sec
[2021-06-06 04:18:01,020 INFO] Step 41450/50000; xent: 2.27; lr: 0.0000147;  30 docs/s;  15275 sec
[2021-06-06 04:18:19,404 INFO] Step 41500/50000; xent: 1.96; lr: 0.0000147;  36 docs/s;  15293 sec
[2021-06-06 04:18:37,540 INFO] Step 41550/50000; xent: 2.00; lr: 0.0000147;  36 docs/s;  15311 sec
[2021-06-06 04:18:56,308 INFO] Step 41600/50000; xent: 2.08; lr: 0.0000147;  32 docs/s;  15330 sec
[2021-06-06 04:19:14,790 INFO] Step 41650/50000; xent: 2.12; lr: 0.0000147;  32 docs/s;  15348 sec
[2021-06-06 04:19:33,340 INFO] Step 41700/50000; xent: 2.19; lr: 0.0000147;  35 docs/s;  15367 sec
[2021-06-06 04:19:51,396 INFO] Step 41750/50000; xent: 1.94; lr: 0.0000147;  34 docs/s;  15385 sec
[2021-06-06 04:20:09,634 INFO] Step 41800/50000; xent: 1.92; lr: 0.0000147;  35 docs/s;  15403 sec
[2021-06-06 04:20:28,230 INFO] Step 41850/50000; xent: 2.02; lr: 0.0000147;  35 docs/s;  15422 sec
[2021-06-06 04:20:46,488 INFO] Step 41900/50000; xent: 2.04; lr: 0.0000147;  34 docs/s;  15440 sec
[2021-06-06 04:21:04,433 INFO] Step 41950/50000; xent: 2.06; lr: 0.0000146;  38 docs/s;  15458 sec
[2021-06-06 04:21:22,756 INFO] Step 42000/50000; xent: 2.15; lr: 0.0000146;  32 docs/s;  15476 sec
[2021-06-06 04:21:40,706 INFO] Step 42050/50000; xent: 2.11; lr: 0.0000146;  37 docs/s;  15494 sec
[2021-06-06 04:21:58,857 INFO] Step 42100/50000; xent: 2.04; lr: 0.0000146;  37 docs/s;  15512 sec
[2021-06-06 04:22:17,336 INFO] Step 42150/50000; xent: 2.09; lr: 0.0000146;  34 docs/s;  15531 sec
[2021-06-06 04:22:35,889 INFO] Step 42200/50000; xent: 2.04; lr: 0.0000146;  37 docs/s;  15549 sec
[2021-06-06 04:22:54,209 INFO] Step 42250/50000; xent: 2.17; lr: 0.0000146;  33 docs/s;  15568 sec
[2021-06-06 04:23:12,322 INFO] Step 42300/50000; xent: 2.06; lr: 0.0000146;  35 docs/s;  15586 sec
[2021-06-06 04:23:30,642 INFO] Step 42350/50000; xent: 1.86; lr: 0.0000146;  36 docs/s;  15604 sec
[2021-06-06 04:23:48,901 INFO] Step 42400/50000; xent: 2.03; lr: 0.0000146;  34 docs/s;  15622 sec
[2021-06-06 04:24:07,140 INFO] Step 42450/50000; xent: 1.96; lr: 0.0000146;  37 docs/s;  15641 sec
[2021-06-06 04:24:25,637 INFO] Step 42500/50000; xent: 1.96; lr: 0.0000146;  35 docs/s;  15659 sec
[2021-06-06 04:24:44,221 INFO] Step 42550/50000; xent: 1.95; lr: 0.0000145;  37 docs/s;  15678 sec
[2021-06-06 04:25:02,460 INFO] Step 42600/50000; xent: 2.34; lr: 0.0000145;  31 docs/s;  15696 sec
[2021-06-06 04:25:20,546 INFO] Step 42650/50000; xent: 2.05; lr: 0.0000145;  35 docs/s;  15714 sec
[2021-06-06 04:25:38,812 INFO] Step 42700/50000; xent: 1.91; lr: 0.0000145;  37 docs/s;  15732 sec
[2021-06-06 04:25:57,208 INFO] Step 42750/50000; xent: 1.97; lr: 0.0000145;  37 docs/s;  15751 sec
[2021-06-06 04:26:15,533 INFO] Step 42800/50000; xent: 2.16; lr: 0.0000145;  31 docs/s;  15769 sec
[2021-06-06 04:26:33,827 INFO] Step 42850/50000; xent: 1.95; lr: 0.0000145;  36 docs/s;  15787 sec
[2021-06-06 04:26:52,277 INFO] Step 42900/50000; xent: 2.13; lr: 0.0000145;  34 docs/s;  15806 sec
[2021-06-06 04:27:10,589 INFO] Step 42950/50000; xent: 1.89; lr: 0.0000145;  38 docs/s;  15824 sec
[2021-06-06 04:27:29,215 INFO] Step 43000/50000; xent: 2.05; lr: 0.0000145;  34 docs/s;  15843 sec
[2021-06-06 04:27:47,519 INFO] Step 43050/50000; xent: 2.03; lr: 0.0000145;  33 docs/s;  15861 sec
[2021-06-06 04:28:05,558 INFO] Step 43100/50000; xent: 1.85; lr: 0.0000145;  42 docs/s;  15879 sec
[2021-06-06 04:28:23,885 INFO] Step 43150/50000; xent: 1.84; lr: 0.0000144;  40 docs/s;  15897 sec
[2021-06-06 04:28:28,973 INFO] Loading train dataset from ../bert_data/train.0.bert.pt, number of examples: 15814
[2021-06-06 04:28:44,601 INFO] Step 43200/50000; xent: 2.18; lr: 0.0000144;  31 docs/s;  15918 sec
[2021-06-06 04:29:02,755 INFO] Step 43250/50000; xent: 2.05; lr: 0.0000144;  34 docs/s;  15936 sec
[2021-06-06 04:29:21,164 INFO] Step 43300/50000; xent: 1.96; lr: 0.0000144;  40 docs/s;  15955 sec
[2021-06-06 04:29:39,111 INFO] Step 43350/50000; xent: 2.29; lr: 0.0000144;  33 docs/s;  15973 sec
[2021-06-06 04:29:57,196 INFO] Step 43400/50000; xent: 2.12; lr: 0.0000144;  36 docs/s;  15991 sec
[2021-06-06 04:30:15,599 INFO] Step 43450/50000; xent: 1.96; lr: 0.0000144;  38 docs/s;  16009 sec
[2021-06-06 04:30:33,767 INFO] Step 43500/50000; xent: 2.43; lr: 0.0000144;  30 docs/s;  16027 sec
[2021-06-06 04:30:51,934 INFO] Step 43550/50000; xent: 2.19; lr: 0.0000144;  33 docs/s;  16045 sec
[2021-06-06 04:31:10,066 INFO] Step 43600/50000; xent: 2.14; lr: 0.0000144;  39 docs/s;  16064 sec
[2021-06-06 04:31:28,266 INFO] Step 43650/50000; xent: 2.01; lr: 0.0000144;  34 docs/s;  16082 sec
[2021-06-06 04:31:46,400 INFO] Step 43700/50000; xent: 2.17; lr: 0.0000144;  35 docs/s;  16100 sec
[2021-06-06 04:32:04,522 INFO] Step 43750/50000; xent: 2.16; lr: 0.0000143;  33 docs/s;  16118 sec
[2021-06-06 04:32:22,673 INFO] Step 43800/50000; xent: 2.20; lr: 0.0000143;  32 docs/s;  16136 sec
[2021-06-06 04:32:40,730 INFO] Step 43850/50000; xent: 2.21; lr: 0.0000143;  32 docs/s;  16154 sec
[2021-06-06 04:32:59,151 INFO] Step 43900/50000; xent: 2.03; lr: 0.0000143;  38 docs/s;  16173 sec
[2021-06-06 04:33:17,333 INFO] Step 43950/50000; xent: 2.34; lr: 0.0000143;  33 docs/s;  16191 sec
[2021-06-06 04:33:35,645 INFO] Step 44000/50000; xent: 2.20; lr: 0.0000143;  32 docs/s;  16209 sec
[2021-06-06 04:33:53,742 INFO] Step 44050/50000; xent: 2.06; lr: 0.0000143;  34 docs/s;  16227 sec
[2021-06-06 04:34:11,645 INFO] Step 44100/50000; xent: 2.23; lr: 0.0000143;  34 docs/s;  16245 sec
[2021-06-06 04:34:30,141 INFO] Step 44150/50000; xent: 2.07; lr: 0.0000143;  36 docs/s;  16264 sec
[2021-06-06 04:34:48,152 INFO] Step 44200/50000; xent: 2.25; lr: 0.0000143;  33 docs/s;  16282 sec
[2021-06-06 04:35:06,623 INFO] Step 44250/50000; xent: 2.25; lr: 0.0000143;  32 docs/s;  16300 sec
[2021-06-06 04:35:24,808 INFO] Step 44300/50000; xent: 2.04; lr: 0.0000143;  35 docs/s;  16318 sec
[2021-06-06 04:35:43,201 INFO] Step 44350/50000; xent: 2.11; lr: 0.0000142;  33 docs/s;  16337 sec
[2021-06-06 04:36:01,417 INFO] Step 44400/50000; xent: 2.18; lr: 0.0000142;  35 docs/s;  16355 sec
[2021-06-06 04:36:19,416 INFO] Step 44450/50000; xent: 2.06; lr: 0.0000142;  37 docs/s;  16373 sec
[2021-06-06 04:36:37,274 INFO] Step 44500/50000; xent: 2.08; lr: 0.0000142;  35 docs/s;  16391 sec
[2021-06-06 04:36:55,847 INFO] Step 44550/50000; xent: 2.15; lr: 0.0000142;  35 docs/s;  16409 sec
[2021-06-06 04:37:14,008 INFO] Step 44600/50000; xent: 2.05; lr: 0.0000142;  35 docs/s;  16427 sec
[2021-06-06 04:37:32,348 INFO] Step 44650/50000; xent: 2.22; lr: 0.0000142;  32 docs/s;  16446 sec
[2021-06-06 04:37:50,313 INFO] Step 44700/50000; xent: 2.14; lr: 0.0000142;  33 docs/s;  16464 sec
[2021-06-06 04:38:08,649 INFO] Step 44750/50000; xent: 2.07; lr: 0.0000142;  36 docs/s;  16482 sec
[2021-06-06 04:38:26,691 INFO] Step 44800/50000; xent: 2.20; lr: 0.0000142;  32 docs/s;  16500 sec
[2021-06-06 04:38:45,042 INFO] Step 44850/50000; xent: 2.09; lr: 0.0000142;  35 docs/s;  16519 sec
[2021-06-06 04:39:03,144 INFO] Step 44900/50000; xent: 2.10; lr: 0.0000142;  34 docs/s;  16537 sec
[2021-06-06 04:39:21,290 INFO] Step 44950/50000; xent: 2.20; lr: 0.0000141;  29 docs/s;  16555 sec
[2021-06-06 04:39:39,496 INFO] Step 45000/50000; xent: 2.21; lr: 0.0000141;  34 docs/s;  16573 sec
[2021-06-06 04:39:39,498 INFO] Saving checkpoint ../models/bert_ext\model_step_45000.pt
[2021-06-06 04:40:04,127 INFO] Step 45050/50000; xent: 2.07; lr: 0.0000141;  28 docs/s;  16598 sec
[2021-06-06 04:40:22,131 INFO] Step 45100/50000; xent: 2.12; lr: 0.0000141;  34 docs/s;  16616 sec
[2021-06-06 04:40:40,690 INFO] Step 45150/50000; xent: 1.96; lr: 0.0000141;  35 docs/s;  16634 sec
[2021-06-06 04:40:58,759 INFO] Step 45200/50000; xent: 2.29; lr: 0.0000141;  30 docs/s;  16652 sec
[2021-06-06 04:41:16,862 INFO] Step 45250/50000; xent: 2.31; lr: 0.0000141;  32 docs/s;  16670 sec
[2021-06-06 04:41:35,152 INFO] Step 45300/50000; xent: 2.10; lr: 0.0000141;  37 docs/s;  16689 sec
[2021-06-06 04:41:53,181 INFO] Step 45350/50000; xent: 2.32; lr: 0.0000141;  34 docs/s;  16707 sec
[2021-06-06 04:42:11,335 INFO] Step 45400/50000; xent: 1.99; lr: 0.0000141;  37 docs/s;  16725 sec
[2021-06-06 04:42:29,570 INFO] Step 45450/50000; xent: 1.99; lr: 0.0000141;  36 docs/s;  16743 sec
[2021-06-06 04:42:47,898 INFO] Step 45500/50000; xent: 2.23; lr: 0.0000141;  35 docs/s;  16761 sec
[2021-06-06 04:43:05,855 INFO] Step 45550/50000; xent: 2.33; lr: 0.0000141;  31 docs/s;  16779 sec
[2021-06-06 04:43:24,277 INFO] Step 45600/50000; xent: 2.03; lr: 0.0000140;  37 docs/s;  16798 sec
[2021-06-06 04:43:42,953 INFO] Step 45650/50000; xent: 2.17; lr: 0.0000140;  33 docs/s;  16816 sec
[2021-06-06 04:44:01,297 INFO] Loading train dataset from ../bert_data/train.4.bert.pt, number of examples: 15873
[2021-06-06 04:44:03,201 INFO] Step 45700/50000; xent: 2.28; lr: 0.0000140;  29 docs/s;  16837 sec
[2021-06-06 04:44:21,646 INFO] Step 45750/50000; xent: 2.08; lr: 0.0000140;  36 docs/s;  16855 sec
[2021-06-06 04:44:40,148 INFO] Step 45800/50000; xent: 2.19; lr: 0.0000140;  34 docs/s;  16874 sec
[2021-06-06 04:44:58,519 INFO] Step 45850/50000; xent: 2.23; lr: 0.0000140;  31 docs/s;  16892 sec
[2021-06-06 04:45:16,806 INFO] Step 45900/50000; xent: 1.91; lr: 0.0000140;  35 docs/s;  16910 sec
[2021-06-06 04:45:35,423 INFO] Step 45950/50000; xent: 2.24; lr: 0.0000140;  30 docs/s;  16929 sec
[2021-06-06 04:45:53,476 INFO] Step 46000/50000; xent: 2.00; lr: 0.0000140;  35 docs/s;  16947 sec
[2021-06-06 04:46:11,655 INFO] Step 46050/50000; xent: 2.11; lr: 0.0000140;  34 docs/s;  16965 sec
[2021-06-06 04:46:29,829 INFO] Step 46100/50000; xent: 2.12; lr: 0.0000140;  32 docs/s;  16983 sec
[2021-06-06 04:46:48,259 INFO] Step 46150/50000; xent: 2.08; lr: 0.0000140;  36 docs/s;  17002 sec
[2021-06-06 04:47:06,750 INFO] Step 46200/50000; xent: 2.07; lr: 0.0000140;  35 docs/s;  17020 sec
[2021-06-06 04:47:25,456 INFO] Step 46250/50000; xent: 2.05; lr: 0.0000139;  31 docs/s;  17039 sec
[2021-06-06 04:47:43,850 INFO] Step 46300/50000; xent: 2.04; lr: 0.0000139;  34 docs/s;  17057 sec
[2021-06-06 04:48:01,943 INFO] Step 46350/50000; xent: 2.10; lr: 0.0000139;  32 docs/s;  17075 sec
[2021-06-06 04:48:20,327 INFO] Step 46400/50000; xent: 2.18; lr: 0.0000139;  33 docs/s;  17094 sec
[2021-06-06 04:48:38,342 INFO] Step 46450/50000; xent: 1.82; lr: 0.0000139;  37 docs/s;  17112 sec
[2021-06-06 04:48:56,758 INFO] Step 46500/50000; xent: 2.03; lr: 0.0000139;  33 docs/s;  17130 sec
[2021-06-06 04:49:14,972 INFO] Step 46550/50000; xent: 1.86; lr: 0.0000139;  36 docs/s;  17148 sec
[2021-06-06 04:49:33,311 INFO] Step 46600/50000; xent: 2.10; lr: 0.0000139;  31 docs/s;  17167 sec
[2021-06-06 04:49:51,649 INFO] Step 46650/50000; xent: 1.93; lr: 0.0000139;  33 docs/s;  17185 sec
[2021-06-06 04:50:10,097 INFO] Step 46700/50000; xent: 2.01; lr: 0.0000139;  36 docs/s;  17204 sec
[2021-06-06 04:50:28,249 INFO] Step 46750/50000; xent: 2.08; lr: 0.0000139;  35 docs/s;  17222 sec
[2021-06-06 04:50:46,563 INFO] Step 46800/50000; xent: 2.00; lr: 0.0000139;  36 docs/s;  17240 sec
[2021-06-06 04:51:04,679 INFO] Step 46850/50000; xent: 1.97; lr: 0.0000139;  36 docs/s;  17258 sec
[2021-06-06 04:51:23,081 INFO] Step 46900/50000; xent: 2.04; lr: 0.0000139;  34 docs/s;  17277 sec
[2021-06-06 04:51:41,422 INFO] Step 46950/50000; xent: 2.07; lr: 0.0000138;  33 docs/s;  17295 sec
[2021-06-06 04:51:59,713 INFO] Step 47000/50000; xent: 1.71; lr: 0.0000138;  42 docs/s;  17313 sec
[2021-06-06 04:52:18,329 INFO] Step 47050/50000; xent: 2.18; lr: 0.0000138;  30 docs/s;  17332 sec
[2021-06-06 04:52:36,292 INFO] Step 47100/50000; xent: 1.99; lr: 0.0000138;  38 docs/s;  17350 sec
[2021-06-06 04:52:54,960 INFO] Step 47150/50000; xent: 2.10; lr: 0.0000138;  32 docs/s;  17368 sec
[2021-06-06 04:53:13,287 INFO] Step 47200/50000; xent: 2.02; lr: 0.0000138;  32 docs/s;  17387 sec
[2021-06-06 04:53:31,435 INFO] Step 47250/50000; xent: 2.00; lr: 0.0000138;  35 docs/s;  17405 sec
[2021-06-06 04:53:50,249 INFO] Step 47300/50000; xent: 2.12; lr: 0.0000138;  34 docs/s;  17424 sec
[2021-06-06 04:54:08,626 INFO] Step 47350/50000; xent: 1.95; lr: 0.0000138;  36 docs/s;  17442 sec
[2021-06-06 04:54:26,792 INFO] Step 47400/50000; xent: 2.32; lr: 0.0000138;  29 docs/s;  17460 sec
[2021-06-06 04:54:45,256 INFO] Step 47450/50000; xent: 2.03; lr: 0.0000138;  33 docs/s;  17479 sec
[2021-06-06 04:55:03,751 INFO] Step 47500/50000; xent: 1.87; lr: 0.0000138;  37 docs/s;  17497 sec
[2021-06-06 04:55:22,132 INFO] Step 47550/50000; xent: 1.80; lr: 0.0000138;  38 docs/s;  17516 sec
[2021-06-06 04:55:40,332 INFO] Step 47600/50000; xent: 1.98; lr: 0.0000138;  36 docs/s;  17534 sec
[2021-06-06 04:55:58,615 INFO] Step 47650/50000; xent: 2.16; lr: 0.0000137;  32 docs/s;  17552 sec
[2021-06-06 04:56:16,807 INFO] Step 47700/50000; xent: 1.93; lr: 0.0000137;  35 docs/s;  17570 sec
[2021-06-06 04:56:35,194 INFO] Step 47750/50000; xent: 2.03; lr: 0.0000137;  32 docs/s;  17589 sec
[2021-06-06 04:56:53,300 INFO] Step 47800/50000; xent: 2.07; lr: 0.0000137;  35 docs/s;  17607 sec
[2021-06-06 04:57:11,585 INFO] Step 47850/50000; xent: 1.97; lr: 0.0000137;  33 docs/s;  17625 sec
[2021-06-06 04:57:29,750 INFO] Step 47900/50000; xent: 2.17; lr: 0.0000137;  32 docs/s;  17643 sec
[2021-06-06 04:57:47,909 INFO] Step 47950/50000; xent: 2.00; lr: 0.0000137;  33 docs/s;  17661 sec
[2021-06-06 04:58:06,254 INFO] Step 48000/50000; xent: 1.93; lr: 0.0000137;  38 docs/s;  17680 sec
[2021-06-06 04:58:24,550 INFO] Step 48050/50000; xent: 2.08; lr: 0.0000137;  32 docs/s;  17698 sec
[2021-06-06 04:58:42,827 INFO] Step 48100/50000; xent: 1.94; lr: 0.0000137;  35 docs/s;  17716 sec
[2021-06-06 04:59:01,579 INFO] Step 48150/50000; xent: 1.95; lr: 0.0000137;  38 docs/s;  17735 sec
[2021-06-06 04:59:20,072 INFO] Step 48200/50000; xent: 2.06; lr: 0.0000137;  35 docs/s;  17754 sec
[2021-06-06 04:59:34,512 INFO] Loading train dataset from ../bert_data/train.3.bert.pt, number of examples: 15918
[2021-06-06 04:59:40,477 INFO] Step 48250/50000; xent: 2.10; lr: 0.0000137;  28 docs/s;  17774 sec
[2021-06-06 04:59:58,580 INFO] Step 48300/50000; xent: 2.10; lr: 0.0000137;  32 docs/s;  17792 sec
[2021-06-06 05:00:16,812 INFO] Step 48350/50000; xent: 2.18; lr: 0.0000136;  31 docs/s;  17810 sec
[2021-06-06 05:00:34,831 INFO] Step 48400/50000; xent: 2.12; lr: 0.0000136;  30 docs/s;  17828 sec
[2021-06-06 05:00:52,899 INFO] Step 48450/50000; xent: 2.14; lr: 0.0000136;  30 docs/s;  17846 sec
[2021-06-06 05:01:11,124 INFO] Step 48500/50000; xent: 2.08; lr: 0.0000136;  30 docs/s;  17865 sec
[2021-06-06 05:01:29,554 INFO] Step 48550/50000; xent: 2.00; lr: 0.0000136;  34 docs/s;  17883 sec
[2021-06-06 05:01:47,845 INFO] Step 48600/50000; xent: 2.29; lr: 0.0000136;  30 docs/s;  17901 sec
[2021-06-06 05:02:06,235 INFO] Step 48650/50000; xent: 2.11; lr: 0.0000136;  30 docs/s;  17920 sec
[2021-06-06 05:02:24,880 INFO] Step 48700/50000; xent: 1.91; lr: 0.0000136;  33 docs/s;  17938 sec
[2021-06-06 05:02:43,305 INFO] Step 48750/50000; xent: 2.07; lr: 0.0000136;  32 docs/s;  17957 sec
[2021-06-06 05:03:01,735 INFO] Step 48800/50000; xent: 2.11; lr: 0.0000136;  34 docs/s;  17975 sec
[2021-06-06 05:03:19,852 INFO] Step 48850/50000; xent: 1.90; lr: 0.0000136;  34 docs/s;  17993 sec
[2021-06-06 05:03:38,070 INFO] Step 48900/50000; xent: 2.08; lr: 0.0000136;  32 docs/s;  18012 sec
[2021-06-06 05:03:56,521 INFO] Step 48950/50000; xent: 1.93; lr: 0.0000136;  31 docs/s;  18030 sec
[2021-06-06 05:04:14,665 INFO] Step 49000/50000; xent: 1.97; lr: 0.0000136;  34 docs/s;  18048 sec
[2021-06-06 05:04:33,076 INFO] Step 49050/50000; xent: 2.01; lr: 0.0000135;  34 docs/s;  18067 sec
[2021-06-06 05:04:51,300 INFO] Step 49100/50000; xent: 1.91; lr: 0.0000135;  35 docs/s;  18085 sec
[2021-06-06 05:05:09,915 INFO] Step 49150/50000; xent: 2.11; lr: 0.0000135;  32 docs/s;  18103 sec
[2021-06-06 05:05:28,398 INFO] Step 49200/50000; xent: 1.97; lr: 0.0000135;  36 docs/s;  18122 sec
[2021-06-06 05:05:46,595 INFO] Step 49250/50000; xent: 2.03; lr: 0.0000135;  34 docs/s;  18140 sec
[2021-06-06 05:06:04,725 INFO] Step 49300/50000; xent: 1.87; lr: 0.0000135;  37 docs/s;  18158 sec
[2021-06-06 05:06:23,484 INFO] Step 49350/50000; xent: 2.09; lr: 0.0000135;  30 docs/s;  18177 sec
[2021-06-06 05:06:41,507 INFO] Step 49400/50000; xent: 1.91; lr: 0.0000135;  33 docs/s;  18195 sec
[2021-06-06 05:06:59,920 INFO] Step 49450/50000; xent: 1.94; lr: 0.0000135;  36 docs/s;  18213 sec
[2021-06-06 05:07:18,409 INFO] Step 49500/50000; xent: 2.11; lr: 0.0000135;  31 docs/s;  18232 sec
[2021-06-06 05:07:36,901 INFO] Step 49550/50000; xent: 1.88; lr: 0.0000135;  35 docs/s;  18250 sec
[2021-06-06 05:07:55,096 INFO] Step 49600/50000; xent: 2.02; lr: 0.0000135;  32 docs/s;  18269 sec
[2021-06-06 05:08:13,364 INFO] Step 49650/50000; xent: 2.09; lr: 0.0000135;  34 docs/s;  18287 sec
[2021-06-06 05:08:31,485 INFO] Step 49700/50000; xent: 2.13; lr: 0.0000135;  31 docs/s;  18305 sec
[2021-06-06 05:08:50,055 INFO] Step 49750/50000; xent: 2.01; lr: 0.0000135;  33 docs/s;  18324 sec
[2021-06-06 05:09:08,265 INFO] Step 49800/50000; xent: 2.11; lr: 0.0000134;  29 docs/s;  18342 sec
[2021-06-06 05:09:27,242 INFO] Step 49850/50000; xent: 1.97; lr: 0.0000134;  32 docs/s;  18361 sec
[2021-06-06 05:09:45,498 INFO] Step 49900/50000; xent: 2.10; lr: 0.0000134;  31 docs/s;  18379 sec
[2021-06-06 05:10:03,997 INFO] Step 49950/50000; xent: 2.13; lr: 0.0000134;  32 docs/s;  18397 sec
[2021-06-06 05:10:22,227 INFO] Step 50000/50000; xent: 2.11; lr: 0.0000134;  31 docs/s;  18416 sec
[2021-06-06 05:10:22,229 INFO] Saving checkpoint ../models/bert_ext\model_step_50000.pt
[2021-06-06 05:10:30,176 INFO] Loading train dataset from ../bert_data/train.4.bert.pt, number of examples: 15873
