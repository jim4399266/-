[model_builder.py 传送门](https://github.com/jim4399266/Text-Summarization/blob/main/week6/src/models/model_builder.py)

[训练log 传送门](https://github.com/jim4399266/Text-Summarization/blob/main/week6/logs/ext_bert)

本次项目感觉难度较大，首先在处理数据的时候比原先复杂，因为目标任务是抽取原文中的句子作为摘要，因此要将数据集中的每条对话拆分成许多小句子，保存到json文件，json文件中，将每一条数据的文本按标点符号拆成小句，  
- 如 “你好，更换全车油水，机油。变速箱油，刹车油，防冻液，清洗节气门，进气管，燃烧室，三元催化。”  
- 变为 [["你", "好"], ["更", "换", "全", "车", "油", "水"], ["机", "油"], ["变", "速", "箱", "油"], ["刹", "车", "油"], ["防", "冻", "液"], ["清", "洗", "节", "气", "门"], ["进", "气", "管"], ["燃", "烧", "室"], ["三", "元", "催", "化"]]  

在这些小句子的前后加上<CLS>和<SEP>标记，组成一个长句，而clss则是长句子中每个小句子的CLS的位置。  
然后再变成pt文件，以字为单位映射成id。
其次，整个项目的训练架构也复杂得多，创建了Train这个类来管理训练中的参数和过程。并且在选择模型、优化器等过程上进行了封装，使得用户输入不同的参数就可以获取不同的模型。  
  
  
由于这周时间较紧，只完成了模型的训练，还未来得及进行模型的测试。
  
  

